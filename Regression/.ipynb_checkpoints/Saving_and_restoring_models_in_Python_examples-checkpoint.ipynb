{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Saving and restoring models in Python\n",
    "Â© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we learn about pickling for saving and restoring a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Learn how to load standard sklearn datasets.\n",
    "* Understand the principle of object serialization.\n",
    "* Learn how to save and restore an Sklearn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Once a model is trained, it is best to **separate the model from the training code** and use it to make predictions going forward. This ensures the model is lightweight and efficient to put into **production**. \n",
    "\n",
    "We often do this by **'saving'** the model: \n",
    "\n",
    ">Saving a model entails storing its parameters and all information needed to make predictons.\n",
    "\n",
    "For example, in the case of a model represented as `y = ax + b`, we would save the `a` and `b` parameters, and the fact that it is a linear model.\n",
    "\n",
    "At this point in the course, you should be familiar with how to train, test and measure the performance of various machine learning models on a given dataset. In this train we cover how to **save** your models into a portable format and **deploy** them in the wild."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data\n",
    "\n",
    "Let's **import** a few Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the **diabetes built-in dataset** which contains a set of predictive variables for predicting some quantitative measure of diabetes disease progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **data description** can be shown as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **create a DataFrame** using the data we have loaded above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['progression'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training the model\n",
    "\n",
    "Let's start by training a model that we can save later.  We'll build a **multiple linear regression** model on the Sklearn's internal dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Having reviewed the data, we now perform a minimal amount of preprocessing to **prepare for model fitting** and **evaluation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "y = df['progression']\n",
    "X = df.drop('progression',axis=1)\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# get training and testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting and evaluation\n",
    "\n",
    "We now fit our model to the data. For this example, we choose a **vanilla linear regression model**, however, we can still explore more complex models within `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get predictions on the test set \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate performance metrics\n",
    "print(\"MSE:\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where visualising how the model performs on the actual data is not possible (i.e. too many dimensions), we can plot the actual vs the predicted `ð‘¦` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred) \n",
    "plt.plot(y_test,y_test,\"r\") # perfect model line\n",
    "plt.ylabel(\"Predicted $y$\")\n",
    "plt.xlabel(\"Actual $y$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance, our MLR model seems to have decent performance. Now let's try to save it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Object Serialization\n",
    "\n",
    "Object serialization is the **storing of variables** and **their values** as a **file**. \n",
    "\n",
    "If we save a standard Python program (i.e. `.py` file), the program needs to be executed before variables can realise their values. \n",
    "\n",
    "For example, think of a saved Jupyter Notebook file (`.ipynb`) where we have to **re-execute all program cells** before we can continue working on our program. \n",
    "\n",
    "In the context of machine learning models, this means we have to **re-train your models** on the original train data before we can use them on other unseeen data. \n",
    "\n",
    ">Object serialization allows us to store our variables and their state as a file, which upon loading can restore the variable and the value it had when we saved it. \n",
    "\n",
    "This way, we can **save** our **sklearn models** along with **their optimal parameters** and **load** them later for reuse.\n",
    "\n",
    "In this train, we will explore **`pickle`**, a common python library for object serialization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model with Pickle\n",
    "\n",
    "Files saved using `pickle` are called ***pickles*** and the process of making them is referred to as ***pickling***. (we know, they took the metaphor quite far...). \n",
    "\n",
    "Luckily for us, saving models using `pickle` follows a similar structure to that of creating or writing to a file in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pickle library\n",
    "import pickle\n",
    "\n",
    "# Save the model just like we would a Python file\n",
    "model_save_path = \"mlr_model.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a **portable `model.pkl` file** in the specified file path which we **can move** between computers, email to others, use for model versioning, etc. We can also use this file to **make predictions** in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring the model with Pickle\n",
    "\n",
    "As you might have guessed, restoring a pickled file is similar to reading a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model just like we would read a file\n",
    "model_load_path = \"mlr_model.pkl\"\n",
    "with open(model_load_path,'rb') as file:\n",
    "    unpickled_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we have loaded our saved model from the load path and loaded it into the `unpickled_model` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model file to make predictions\n",
    "\n",
    "**NB:** Imagine that we are now starting on a new Jupyter Notebook and this was all we put in it.\n",
    "You will notice there is **no data** and **no training** in the code since the model is already trained and the training data is no longer needed.\n",
    "\n",
    "All that's left now is to **load the data into the model** and get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from unpickled model\n",
    "y_pred = unpickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have model predictions that we can use wherever we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance metrics\n",
    "print(\"MSE:\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to keep in mind\n",
    "\n",
    "In order to ensure that the behaviour of your **model is reproducible** after serialization you should keep the following in mind:\n",
    "\n",
    "- **The Python environment dependencies** (version of python packages): Make sure the model is deployed into an identical environment, i.e. `sklearn` versions are the same as in the model training environment.\n",
    "\n",
    "- **The Python version**: It is unreasonble to expect a model trained using `Python 2.7` will work when restored to an environment with `Python 3.6`. As such, it is important to use consistent versions of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A new version of the Pandas package, `Pandas 2`, was released in April 2023. While it comes with added functionality, we continue to use `Pandas 1` in this train for stability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data - pass 'Name' as our index column.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/fundamentals/football_players.csv', index_col='Name')\n",
    "\n",
    "# Use the head() function to look at the first 5 rows.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Serializing your models can be extremely useful, not only can you **save** your models but you can also **re-train** them later when more data is available.  \n",
    "\n",
    "In this train, we covered how to:\n",
    "\n",
    "- Train a multiple linear regression model.\n",
    "- Save the model (i.e. trained model parameters) to a file.\n",
    "- Restore a saved model and use it to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
