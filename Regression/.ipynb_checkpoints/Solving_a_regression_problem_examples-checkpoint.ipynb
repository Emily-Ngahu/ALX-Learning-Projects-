{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Solving a regression problem\n",
    " \n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this train, we look at how to experiment with various modeling methods to solve a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "* Load and prepare a dataset.\n",
    "* Train and evaluate linear, non-linear and ensemble regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "We wish to examine and understand how socio-economic and environmental factors contribute to the rate of deforestation. We have been given a dataset that captures this information. Our goal to to model this relationship through regression analysis. \n",
    "\n",
    "In the sections that follow, we explore the process of training and evaluating various regression models on a similar dataset. Through the model experimentation process, we are able to compare the performance of various models, guiding the selection of the best model for predicting our target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset and libraries\n",
    "\n",
    "We begin by setting up our working environment by importing the necessary `Python` libraries that we will use throughout the notebook\n",
    "\n",
    "Then, we load and inspect the dataset to get familiar with its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/enviro_indicators.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data exploration\n",
    "\n",
    "Here, we will perform a preliminary exploration of our dataset to get a better understanding of the data we are working with.\n",
    "\n",
    "This initial exploration of our data, will help uncover underlying patterns and relationships that can inform our choice of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying data information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data.info()` gives us more information about our columns including their data types and the count of non-null values.\n",
    "\n",
    "It seems we do not have any null values in our dataset. Also, all the features in the dataset are numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a pairwise plot to visualise and understand the relationships among the variables. Using `sns.pairplot()`, we can generate scatter plots for each pair of variables in our dataset, providing a comprehensive overview of how each variable interacts with the others. This can help us identify patterns that may influence our modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only `forest coverage` and `biodiversity_index` show a linear-like relationship with the target variable `deforestation_rate`. This observation suggests the potential of these variables to be strong predictors in a linear regression model. The rest of the variables, however, do not demonstrate a clear linear trend. This indicates more complex relationships that might not be adequately captured by a linear model alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform **correlation analysis** to understand the correlation between the different features present in our dataset and our target variable,`deforestation_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation coefficients\n",
    "correlation_matrix = data.corr()\n",
    "correlation_with_target = correlation_matrix['deforestation_rate'].sort_values(ascending=False)\n",
    "\n",
    "# Display the correlations with the target variable\n",
    "print(\"Correlation of features with deforestation rate:\\n\", correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `.corr()` to calculate the correlation matrix for our dataset, then filtered the result to only contain the correlation coefficients related to the `deforestation_rate` column and sort them from the highest to the lowest. The results show that biodiversity_index, forest_coverage, population_density and protected_areas have some relationship with deforestation_rate. \n",
    "\n",
    "This way, we we can identify strong predictors for `deforestation_rate`.\n",
    "\n",
    "**Note:** We need to consider both the positive and negative correlations, that is, the **highest positive** and the **highest negative values**. Alternatively, we can use `.abs` method to obtain the absolute values of the correlations, allowing us to sort them regardless of their direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot a heatmap visualisation to further aid in understanding these relationships, highlighting the most significant correlations. This image makes it easy to also see relationship between the predictive variables, something that is good to keep in mind when doing regression analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Enviro Indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data preprocessing\n",
    "\n",
    "We prepare the data for modeling by splitting it into training and testing sets and scaling the features to help our models perform optimally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the feature and target variables\n",
    "X = data.drop(['deforestation_rate'], axis=1)\n",
    "y = data['deforestation_rate']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "# Initialize and apply MinMaxScaler for scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code block, we prepare our features `X` and target variable `y` for modeling. The dataset is also split into training and testing sets, and feature scaling is applied using `MinMaxScaler`. This process ensures that our regression models do not bias towards variables with larger magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training and evaluation\n",
    "\n",
    "### 5.1 Simple linear regression model\n",
    "\n",
    "Our journey into model training begins with a simple linear regression model. This model, while simple, serves as a great baseline to compare more complex models against. \n",
    "\n",
    "A simple linear regression model uses only one independent variable to predict the dependent variable.\n",
    "\n",
    "From the correlation analysis we performed above, we observed that `biodiversity_index` had the strongest correlation with our target variable and also demonstrated a linear relationship. This makes it a good candidate as the predictor variable for our SLRM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for simple linear regression\n",
    "\n",
    "X_train_lr = pd.DataFrame(X_train_scaled, columns=X.columns)[['biodiversity_index']]\n",
    "X_test_lr = pd.DataFrame(X_test_scaled, columns=X.columns)[['biodiversity_index']]\n",
    "\n",
    "# Training the model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train_lr, y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred_lr = model_lr.predict(X_test_lr)\n",
    "\n",
    "# Evaluating the model\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred_lr)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_lr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, we convert the scaled arrays back into DataFrames to maintain the ability to reference columns by name.\n",
    "\n",
    "Our simple linear regression model performed relatively well with an R-squared value above 0.7, but it could probably be improved on by adding a few more variables to the model. Let's see how this compares to the performance of other more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Other regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's expand our analysis by applying more complex models. Exploring these models will help us capture more complex patterns that a simple linear model might miss. This can, in turn, improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A generic function for model training and evaluation:\n",
    "\n",
    "Let's develop a general function that we can use to train and test various regression models. This will enhance re-usability and reduce redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model):\n",
    "    \n",
    "    # Train the model on the scaled training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the scaled test set\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    \n",
    "    return model, r2, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_and_evaluate_model` function trains the provided model on the preprocessed and scaled training data, evaluates it against the test set, and returns the trained model along with its R² and Mean Squared Error (MSE) scores.\n",
    "\n",
    "**Note:** While using a generic function for model training and evaluation is a good idea for simplicity and efficiency, it may be limiting in some cases such as where the data or the importance of features varies across models. In such cases, we can train and evaluate each model separately to tailor the selection of features and fine-tune the model's performance to the specific characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Multiple linear regression model\n",
    "\n",
    "We apply the previously defined function to train and evaluate a multiple linear regression model, where we use all available features (after scaling) to predict the rate of deforestation. This way, we get to leverage the predictive value of the rest of the features.\n",
    "\n",
    "We get to observe how a more complex linear approach compares to the simpler, single-variable linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluating the multiple linear regression model\n",
    "linear_model, linear_r2, linear_mse = train_and_evaluate_model(LinearRegression())\n",
    "print(f\"Linear regression - R²: {linear_r2}, MSE: {linear_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has performed better, given the increase in R2 score and a decrease in the MSE. It would be interesting to test this model with only the strongest predictors as well - it could be informative to assess whether there is a big drop in predictive power if we drop some of the weaker predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Decision tree regression model\n",
    "\n",
    "We apply the previously defined function to train and evaluate a decision tree regression model. This allows us to explore the capabilities of a non-linear model in capturing the non-linear patterns we earlier observed in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluating the decision tree regression model\n",
    "tree_model, tree_r2, tree_mse = train_and_evaluate_model(DecisionTreeRegressor(random_state=42, max_depth=4))\n",
    "print(f\"Decision tree regression - R²: {tree_r2}, MSE: {tree_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree does not perform as well as expected. It could be because there are several variables included that don't hold that much predictive power, or the fact that our tree has a max_depth parameter that was set to 4, which is quite shallow. Ideally, we should run multiple iterations of decision trees, with different parameters to determine the optimal fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Ensemble models\n",
    "\n",
    "We have so far only trained stand alone models. Here, we want to apply ensembling techniques where we combine multiple machine learning models in an attempt to improve predictive performance. Let's try out both a homogeneous and a heterogeneous ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Random forest regression model\n",
    "\n",
    "We apply the previously defined function to train and evaluate a random forest regression model. It leverages the the power of homogenous ensemble learning by combining multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluating the random forest regression model\n",
    "forest_model, forest_r2, forest_mse = train_and_evaluate_model(RandomForestRegressor(random_state=42, max_depth=4))\n",
    "print(f\"Random Forest Regression - R²: {forest_r2}, MSE: {forest_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement in the performance of our model. This is because random forests, by aggregating the predictions of numerous decision trees, reduce the risk of overfitting and offer a more generalisable model. Again, try testing it with different levels of max_depth to see what the outcomes are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Stacking ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try and capitalise on the unique strengths of other different model types than just the decision trees. To be precise, we will apply stacking where we will train a meta-learner based on the outputs of some base models.\n",
    "\n",
    "We will use some of the models we have already trained as our base learners and a new model as the meta-learner.\n",
    "\n",
    "Let's start by defining our base models and the meta-learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base models: these are models that have already been trained\n",
    "base_models = [\n",
    "    ('linear_regression', linear_model),\n",
    "    ('random_forest', forest_model)\n",
    "]\n",
    "\n",
    "# Define the meta-learner\n",
    "final_estimator = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply our generic function to train and evaluate a stacking regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluating the stacking regression model\n",
    "stacking_model, stacking_r2, stacking_mse = train_and_evaluate_model(StackingRegressor(estimators=base_models, final_estimator=final_estimator, cv=5))\n",
    "print(f\"Stacking Regression - R²: {stacking_r2}, MSE: {stacking_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the `StackingRegressor` from `scikit-learn`, specifying our previously trained multiple linear regression, and random forest models as the base models and a linear regression model as the final estimator. \n",
    "\n",
    "We note a marginal improvement in performance in comparison to the stand alone models, but should also consider whether the cost (in terms of time and memory), is worth the improvement in predictive powers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our journey to solve a regression problem, we have explored different modeling options, each offering different strengths that could be used to solve the problem at hand. In the end, our goal is to achieve a good balance between performance and simplicity, and remember, more advanced models may not always be the best, despite convincing metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
