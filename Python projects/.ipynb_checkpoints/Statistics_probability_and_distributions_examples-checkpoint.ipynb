{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a87da4",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cdeff5",
   "metadata": {},
   "source": [
    "# Examples: Probability and distributions\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d556290",
   "metadata": {},
   "source": [
    "In this notebook, we'll cover statistical concepts, probability, and different types of distributions that can be used to analyse data using the `scipy.stats` package script in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d31105",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "- Distinguish between inferential and descriptive statistics.\n",
    "- Describe and identify the different variable and data types.\n",
    "- Utilise the stats package `scipy.stats` in python.\n",
    "- Understand the concepts of random variables.\n",
    "- Understand probability functions.\n",
    "- Differentiate and explain different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83457db5",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Descriptive and inferential statistics](#descriptive-and-inferential-statistics)\n",
    "2. [Variables and data types](#variables-and-data-types)\n",
    "3. [Probability - the chance of everything happening](#probability---the-chance-of-everything-happening)\n",
    "4. [Probability mass and probability density functions](#probability-mass-and-probability-density-functions)\n",
    "\n",
    "6. [Distributions in statistics](#distributions-in-statistics)\n",
    "   * [Normal distribution](#normal-distribution)\n",
    "   * [Binomial distribution](#binomial-distribution)\n",
    "   * [Poisson distribution](#poisson-distribution)\n",
    "   * [Negative binomial distribution](#negative-binomial-distribution)\n",
    "   * [Exponential distribution](#exponential-distribution)\n",
    "   * [Uniform distribution](#uniform-distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f0fee0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Within the realm of data, probabilities and distributions are extremely important. These concepts will provide a vital basis when moving on to related technical fields such as machine learning, modeling, and algorithmic development.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89045777",
   "metadata": {},
   "source": [
    "## Descriptive and inferential statistics\n",
    "\n",
    "The two main branches of statistics are **descriptive** and **inferential** statistics.  \n",
    "\n",
    "The best comparison between the two is described in Keone Hon's *Introduction to Statistics*: \"Descriptive statistics is used to say something about a set of information that has been collected only. Inferential statistics is used to make predictions or comparisons about a larger group (a population) using information gathered about a small part of that population. Thus, inferential statistics involves generalizing beyond the data, something that descriptive statistics does not do.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e1ce6",
   "metadata": {},
   "source": [
    "### Descriptive statistics\n",
    "\n",
    "Descriptive statistics summarise and describe the main features of a dataset. This includes **measures of central tendency** (mean, median, mode) and **measures of variability** (range, variance, standard deviation).\n",
    "\n",
    "Let's examine a simple dataset on deforestation rates in various regions to calculate basic descriptive statistics for the year 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf9f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       4.00000\n",
      "mean      612.50000\n",
      "std       342.47871\n",
      "min       200.00000\n",
      "25%       425.00000\n",
      "50%       625.00000\n",
      "75%       812.50000\n",
      "max      1000.00000\n",
      "Name: Deforestation_rate_2020, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Deforestation rates (in hectares) in various regions\n",
    "data = {\n",
    "    'Region': ['Amazon', 'Congo', 'Southeast Asia', 'Boreal Forests'],\n",
    "    'Deforestation_rate_2020': [1000, 500, 750, 200],  # Ratio variable\n",
    "    'Deforestation_rate_2021': [800, 450, 700, 150],  # Ratio variable, assuming a decrease\n",
    "    'Region_type': ['Tropical', 'Tropical', 'Tropical', 'Temperate']  # Nominal variable\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate basic descriptive statistics\n",
    "descriptive_stats = df['Deforestation_rate_2020'].describe()\n",
    "print(descriptive_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c406a8",
   "metadata": {},
   "source": [
    "### Inferential statistics\n",
    "\n",
    "Inferential statistics involve making predictions or inferences about a population based on a sample of data. It includes hypothesis testing, confidence intervals, and regression analysis.\n",
    "\n",
    "Building on our descriptive statistics, let's test the hypothesis that deforestation rates have decreased in 2021 due to new environmental policies by comparing 2020 and 2021 data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32915dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate mean deforestation rates for 2020 and 2021\n",
    "mean_deforestation_2020 = np.mean(df['Deforestation_rate_2020'])\n",
    "mean_deforestation_2021 = np.mean(df['Deforestation_rate_2021'])\n",
    "\n",
    "# Data for plotting\n",
    "years = ['2020', '2021']\n",
    "means = [mean_deforestation_2020, mean_deforestation_2021]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(years, means, color=['blue', 'green'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Mean Deforestation Rate (hectares)')\n",
    "plt.title('Mean Deforestation Rate Comparison: 2020 vs. 2021')\n",
    "plt.xticks(years)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb19101",
   "metadata": {},
   "source": [
    "The result suggests that there might have been an improvement in the deforestation situation from 2020 to 2021, potentially due to new environmental policies or other factors.\n",
    "\n",
    "However, while the bar chart provides a straightforward visual comparison, it does not indicate whether the difference in means is statistically significant. To confirm if the observed difference is not due to random variation, a statistical test like the **t-test**, which is beyond the scope of this notebook, would be required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5925c3",
   "metadata": {},
   "source": [
    "## Variables and data types\n",
    "\n",
    "In statistics, variables can be classified into 2 wide classes:\n",
    "1. **Categorical** \n",
    "2. **Numeric**\n",
    "\n",
    "**In the Categorical class, we have:**\n",
    "1. **Nominal Data**\n",
    "- Binary Data - two distinct outcomes (yes/no or true/false)\n",
    "- Categorical Data -  many data types (primary/secondary/tertiary)\n",
    "\n",
    "2. **Ordinal Data** - A number used in scoring that implies an order. An example is a rank from Low to High \n",
    "\n",
    "\n",
    "**In the Numeric class, we have:**\n",
    "1.  **Continuous Data** \n",
    "- Interval (numerical) data  - Lacks an absolute zero point (temperature in Celsius, year)\n",
    "- Ratio - variable with any number (Rainfall, time, temperature in Kelvin)\n",
    "\n",
    "2.  **Discrete Data** - variables which hold a whole number; can be used as a counting number (Number species in a forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d5be4",
   "metadata": {},
   "source": [
    "Let's add more data to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Average_Rainfall_mm'] = [2300, 1600, 2500, 500]  \n",
    "df['Protected_Area'] = [True, False, True, True]  \n",
    "df['Biodiversity_Index'] = [8.5, 7.0, 9.0, 6.5]  \n",
    "df['Conservation_Status'] = ['High', 'Medium', 'Low', 'Medium']  \n",
    "# Mapping ordinal variable to an ordered numerical representation\n",
    "conservation_mapping = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "df['Conservation_Status_Mapped'] = df['Conservation_Status'].map(conservation_mapping)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc6013",
   "metadata": {},
   "source": [
    "We've introduced an ordinal variable, `Conservation_Status`, to rank regions based on their conservation priority. This variable has an inherent order: Low < Medium < High. We then map these ordinal values to numbers to facilitate statistical analysis, demonstrating a common technique for handling ordinal data in Python.\n",
    "\n",
    "Understanding these variable types and their implications is crucial for accurately analysing and interpreting data. For instance, when analysing deforestation rates, knowing that these rates are ratio variables allows us to calculate meaningful ratios, averages, and perform other statistical analyses that depend on a true zero point. Similarly, recognizing `Region_type` as a nominal variable informs us that statistical tests for independence might be appropriate for analysing relationships involving this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7182525",
   "metadata": {},
   "source": [
    "## Probability - the chance of everything happening\n",
    "\n",
    "This section is going to introduce the world of probability and illustrate how powerful python packages can help to compute the numbers related to probability. \n",
    "\n",
    "It's useful to take a look at basic probalities in *Chapter 3* of [Keone's textbook](https://www.fd.cvut.cz/department/k611/PEDAGOG/THO_A/A_soubory/statistics_firstfive.pdf).\n",
    "We can also see how those concepts are implemented in python [here](https://www.datacamp.com/community/tutorials/statistics-python-tutorial-probability-1).\n",
    "\n",
    "Let's start off by importing some important packages in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st #Read this documentation and refer to documentation on the super stats package\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879eaa2",
   "metadata": {},
   "source": [
    "### Random Variables \n",
    "\n",
    "In probability theory, we define the concept of the sample space $S$ as the set of all possible events; we can think of this as representing all of the possible outcomes of an experiment whose outcome is unknown at the outset. For example, getting dressed in the morning, we reach blindly into the drawer to pull out a pair of socks, knowing that there are white, black and blue socks in there.\n",
    "\n",
    "We can think of this as an experiment: we know what all the possible outcomes are, and if we know something about how many pairs of each colour sock we own, we also know something about the probabilities of those outcomes. But we don't know the actual outcome until we pull our hand back out and examine the pair of socks it's clutching.\n",
    "\n",
    "We can define a variable $X$ to stand for the values of the possible outcomes. This $X$ is what we define as a **random variable**: one which can take on a range of possible values and whose actual value is unknown until completion of the experiment.\n",
    "\n",
    "Other classic examples include the tossing of a coin or the rolling of a die.\n",
    "\n",
    "### Discrete Random Variables \n",
    "\n",
    "Discrete random variables can only take on specific values. Our sock, coin and die examples above are all discrete: the possibilities are {white, black,blue}, {heads, tails} and {1, 2, 3, 4, 5, 6} respectively.\n",
    "\n",
    "Usually, we'll be looking at problems where the outcomes are real numbers, as in the die example. Where they're not, as in the coin example, we would usually proceed by assigning a numeric value to each of the possible outcomes, e.g. 1 for heads and 2 for tails. Most common discrete random variables take on integer values, but that's not necessarily the case: if there are either 2 or 3 people coming to share a pizza with me, and we share equally, then the possible outcomes for me are one-quarter and one-third of a pizza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be89bc5",
   "metadata": {},
   "source": [
    "## Probability mass and probability density functions\n",
    "\n",
    "We need some mathematical language to describe the probabilities of the various possible outcomes of random variables (what we refer to as **probability distributions**). Random variables have functions which map their outcomes onto their corresponding probabilities. These are most easily described in the case of discrete random variables, whose **probability mass functions** $p(x)$ directly map a given outcome $x$ onto the probability of $x$ being observed in a given trial.\n",
    "\n",
    "There are three conditions which a probability mass function (PMF) must fulfill:\n",
    "\n",
    "1. $p(x)$ is defined for all $x$, but $p(x)>0$ only for a finite set of points. (Or countably infinite set of points, but that's a subtlety we can happily ignore at this stage.)\n",
    "\n",
    "2. $0 \\le p(x) \\le 1$ for all $x$. Intuitively, the bounds on a probability are 0 for an outcome that can never be observed and 1 for a certain outcome.\n",
    "\n",
    "3. $\\displaystyle \\sum_x p(x) = 1$. Observing one of the range of all possible outcomes is certain, and hence probabilities must sum to 1.\n",
    "\n",
    "Consider the coin toss, coding heads as 1 and tails as 2. We have that $p(1) = p(2) = 0.5$ and $p(x) = 0$ for all $x \\neq 1,2$, hence all three conditions hold and the probability mass function for the coin toss is a valid PMF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e58f9",
   "metadata": {},
   "source": [
    "**Continuous random variables** are a little more tricky, conceptually. For discrete variables, the probability mass function tells us directly the probability of individual outcomes, or (by summing) of groups of outcomes. \n",
    "\n",
    "For example, the PMF for the roll of a die is $p(x) = 1/6$ for $x \\in 1, 2, 3, 4, 5, 6$. \n",
    "\n",
    "We can see directly that there is a one-in-six chance of rolling a three, or a 50% chance $(1/6 + 1/6 + 1/6)$ of rolling a four or above. But for continuous random variables, the probability of achieving a very specific outcome is in fact zero. This sounds a little counter-intuitive, I know, but it has to do with the infinite divisibility of outcomes. \n",
    "Therefore, for a continuous random variable, we must think in terms of the probability of achieving an outcome between two limits. For example, for the 400m world record, we could think of the probability of Wayde van Niekerk running another 43.03 second race, rounded to the nearest hundredth of a second, as the probability of time between 43.025 and 43.035 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecece9a",
   "metadata": {},
   "source": [
    "We, therefore, can't directly define a probability mass function for continuous random variables; instead, we define what is known as a **probability density function** (PDF). There are also three conditions for PDFs which are conventionally written as $f(x)$:\n",
    "\n",
    "1. $f(x)$ must be defined for all values of $x$.\n",
    "\n",
    "2. All values of $f(x)$ are non-negative (note there is no upper bound on this, unlike $p(x)$ for a discrete random variable).\n",
    "\n",
    "3. Finally, $\\displaystyle \\int_{-\\infty}^{\\infty} f(x) dx = 1$.\n",
    "\n",
    "The last condition is the equivalent of the requirement that all probability masses sum to 1 for a discrete random variable. Probabilities for continuous variables are found by integration, which is after all the continuous analogue to summation, and this condition enforces that the integral of the probability densities over all possible values of $x$ comes to 1, as necessary for a valid probability distribution. To continue with our 400m example, we would evaluate the probability we're after by integrating between 43.025 and 43.035 seconds. We'd find the probability of Wayde breaking his own world record by integrating over the interval 0 (or negative infinity, but negative times are of course not possible so we can safely ignore this part of the real number line) to 43.025 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce3e20",
   "metadata": {},
   "source": [
    "### Cumulative distribution functions\n",
    "\n",
    "Cumulative distribution functions (CDFs, or just distribution functions), usually denoted $F(x)$, give the probability that a random variable $X$ takes on a value less than or equal to some given value $x$. In other words, $$F(x) = P(X \\le x).$$\n",
    "\n",
    "Before reading further, let's see if we can figure out how $F(x)$ would be defined for a discrete and a continuous random variable respectively.\n",
    "\n",
    "That's right: for a discrete variable it would be \n",
    "\n",
    "$$F(x) = \\sum_{t \\le x} p(t),$$ \n",
    "\n",
    "and for a continuous random variable we would define the distribution function as \n",
    "\n",
    "$$F(x) = \\int_{-\\infty}^x f(t) \\: dt.$$\n",
    "\n",
    "\n",
    "If CDFs are still not quite clear, go to [this link](https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-the-pdf-cdf-and-quantile-function) for another explanation of CDF's "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95912947",
   "metadata": {},
   "source": [
    "## Distributions in statistics\n",
    "There are several types of distributions in statistics, each with its applications and assumptions. Key distributions include Normal, Binomial, Poisson, and Exponential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ebcc11",
   "metadata": {},
   "source": [
    "### Normal distribution\n",
    "\n",
    "The Normal distribution, also known as the Gaussian distribution, is a cornerstone of statistical analysis and probability theory due to its **ubiquitous presence in natural and social phenomena**. Its significance lies in the **Central Limit Theorem**, which states that the sum of many independent random variables, each with finite mean and variance, will tend to follow a Normal distribution, regardless of the original distribution of the variables. Here are the key features and the mathematical representation of the Normal distribution:\n",
    "\n",
    "1. **Symmetry**: The Normal distribution is perfectly symmetrical around its mean. This symmetry means that the mean, median, and mode of the distribution are equal.\n",
    "2. **Bell-shaped curve**: It has a distinctive bell-shaped curve, where the probability density decreases rapidly and symmetrically as one moves away from the mean in either direction.\n",
    "3. **Defined by two parameters**: The shape of the Normal distribution is completely specified by two parameters—its mean ($(\\mu)$) and its standard deviation ($(\\sigma)$). The mean determines the location of the center of the graph, and the standard deviation determines the height and width of the graph.\n",
    "\n",
    "4. **Asymptotic**: The tails of the Normal distribution curve approach, but never touch, the horizontal axis. This indicates that no matter how far one moves away from the mean, the probability density never actually reaches zero.\n",
    "\n",
    "5. **Inflection points**: The curve has inflection points at $(\\mu - \\sigma)$ and $(\\mu + \\sigma)$, where the curvature changes direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9de5a9",
   "metadata": {},
   "source": [
    "\n",
    "**Mathematical representation**\n",
    "\n",
    "The probability density function (PDF) of the Normal distribution for a random variable \\(X\\) is given by:\n",
    "\n",
    "$$ f(x) = \\displaystyle \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{1}{2} \\left( \\frac{x-\\mu}{\\sigma} \\right) ^2} $$\n",
    "\n",
    "where:\n",
    "- $(x)$ is the value of the random variable,\n",
    "- $(\\mu)$ is the mean of the distribution,\n",
    "- $(\\sigma)$ is the standard deviation of the distribution, and\n",
    "- $(e)$ is the base of the natural logarithm (\\(\\approx 2.71828\\)).\n",
    "\n",
    "**Properties and usage**\n",
    "\n",
    "- **Standard normal distribution**: When $(\\mu = 0)$ and $(\\sigma = 1)$, the Normal distribution is called the Standard Normal Distribution. It is often denoted by $(Z)$ and is used as a reference to transform other Normal distributions using Z-scores. The PDF is shown below:\n",
    "\n",
    "$$ \\phi(x) = \\displaystyle \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^2} $$\n",
    "\n",
    "- **68-95-99.7 Rule (Empirical Rule)**: About 68% of the data falls within one standard deviation of the mean ($(\\mu \\pm \\sigma)$), 95% within two standard deviations ($(\\mu \\pm 2\\sigma)$), and 99.7% within three standard deviations ($(\\mu \\pm 3\\sigma)$).\n",
    "\n",
    "- **Applicability**: The Normal distribution is used in numerous statistical methods, including hypothesis testing, confidence intervals, and regression analysis. It's also fundamental in the natural and social sciences to describe real-world phenomena where the distribution of variables tends to be symmetrically distributed around a central value.\n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Normal-distribution-68-95-99-rule.png\"  style=\"width:70%\";/>\n",
    "    <br>\n",
    "    <br>\n",
    "    <em>Figure 1: Normal distribution</em>\n",
    "</div>\n",
    "\n",
    "The Normal distribution's mathematical elegance and practical applicability make it a pivotal concept in statistics, underlying many statistical methods and theories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24797fe0",
   "metadata": {},
   "source": [
    "We can use first principles, rather than other built-in functions to show how the density function can be plotted for different mu and sigma values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard normal distribution plot\n",
    "x = np.arange(-5,5,0.01)     # range of values for z\n",
    "mu = 0                       # mu = 0 for standard normal\n",
    "sigma = 1                    # mu = 1 for standard normal\n",
    "\n",
    "# now calculate f(x)\n",
    "f = 1 / np.sqrt ((2 * np.pi * sigma ** 2)) * np.exp (-0.5 * ((x - mu) / sigma) ** 2)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(x,f,'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7ec58",
   "metadata": {},
   "source": [
    "Notation-wise, if $X$ is normally distributed with mean $\\mu$ and standard deviation $\\sigma$, then we denote this as $X \\sim N(\\mu, \\sigma^2)$. Note that the second parameter is by convention shown as $\\sigma^2$ rather than $\\sigma$ - this is the variance of the distribution. \n",
    "\n",
    "Remember that for continuous random variables, to calculate the probability of an outcome in a particular range, we need to use the **cumulative distribution function**. As we've seen above, this requires integrating the **PDF**. While that is currently beyond the scope of this course, more information on integration is available here: https://en.wikipedia.org/wiki/Numerical_integration). Fortunately, Python and `scipy` provide functions for us to evaluate PDFs without the need to integrate or even use the numerical tables that are sometimes provided. \n",
    "\n",
    "Let's define a function to calculate the probability of observation following the above distribution lying between arbitrary bounds $x_1$ and $x_2$, and then use that to calculate the probability of observation between 2 and 5. We use the simple logic here that the probability we're after is the probability of observation of less than $x_2$, less the probability of an observation less than $x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_prob (x1, x2, mu, sigma):\n",
    "    return (st.norm.cdf (x2, mu, sigma) - st.norm.cdf (x1, mu, sigma))\n",
    "\n",
    "normal_prob(2, 5, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15587f",
   "metadata": {},
   "source": [
    "#### Further examples using `scipy.stats` in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cef90b",
   "metadata": {},
   "source": [
    "**Example 1**\n",
    "\n",
    "Now, suppose a study has shown that the optimal temperature range for the growth of a particular tree species involved in reforestation is between 18°C and 22°C. Temperatures outside this range can slow down growth or even cause stress to the trees.\n",
    "\n",
    "Using the Normal distribution, we can calculate not just the probability of exceeding a certain temperature but also the likelihood that the temperature will fall within the optimal range for tree growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7667c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temperature data\n",
    "df['Average_Temperature'] = [25, 24, 27, -5]  # Average annual temperature (°C)\n",
    "df['Temperature_Std_Dev'] = [2, 1.5, 2.5, 3]  # Standard deviation of temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d04e1",
   "metadata": {},
   "source": [
    "To analyse the impact of temperature variations on deforestation, we will model the temperature of each region using the Normal distribution. This approach allows us to assess the likelihood of extreme temperature conditions that could exacerbate or mitigate deforestation rates.\n",
    "\n",
    "For instance, we can calculate the probability of experiencing temperatures above a certain threshold that might lead to increased deforestation due to factors like increased fire risk or altered rainfall patterns.\n",
    "\n",
    "The `norm` function from the `scipy.stats` module represents the normal (Gaussian) distribution. The `norm` function provides several methods for working with the normal distribution, including calculating probabilities, generating random variables, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# Example: Probability of experiencing temperatures above 30°C in Southeast Asia\n",
    "region = 'Southeast Asia'\n",
    "mean_temp = df.loc[df['Region'] == region, 'Average_Temperature'].values[0]\n",
    "std_dev_temp = df.loc[df['Region'] == region, 'Temperature_Std_Dev'].values[0]\n",
    "\n",
    "# Probability of temperature exceeding 30°C\n",
    "prob_above_30 = 1 - norm.cdf(30, mean_temp, std_dev_temp)\n",
    "print(f\"Probability of temperature above 30°C in {region}: {prob_above_30:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9263bf",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "\n",
    "Suppose we're interested in understanding the effectiveness of recent conservation initiatives. Based on our preliminary analysis, we estimate that the mean reduction in deforestation rates since implementation is **250 hectares**, with a standard deviation of **50 hectares**. We are particularly interested in calculating the probability of observing a reduction greater than **300 hectares** in a region, as this would indicate a highly effective conservation effort.\n",
    "\n",
    "To conduct this analysis, we will use the `norm.cdf` function from the `scipy.stats` package in Python, which will allow us to calculate the cumulative distribution function for a normal distribution. This approach will enable us to determine the likelihood of achieving a deforestation rate reduction of more than **300 hectares**, providing us with valuable insights into the effectiveness of conservation initiatives across the studied regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Probability of deforestation rate reduction\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Assuming deforestation rate reduction follows a normal distribution\n",
    "mean_reduction = 250  # Mean reduction in hectares\n",
    "std_deviation = 50  # Standard deviation\n",
    "\n",
    "# Probability of observing a reduction greater than 300 hectares\n",
    "prob_greater_than_300 = 1 - norm.cdf(300, mean_reduction, std_deviation)\n",
    "print(f\"Probability of reduction greater than 300 hectares: {prob_greater_than_300:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26aede",
   "metadata": {},
   "source": [
    "The `cdf` method of the `norm` function stands for **Cumulative Distribution Function**. It gives the probability that a normally distributed random variable with the specified mean and standard deviation is less than or equal to a given value.\n",
    "* `norm.cdf(300, mean_reduction, std_deviation)` calculates the probability that the reduction is less than or equal to 300 hectares.\n",
    "* Subtracting this value from 1 gives the probability of the reduction being greater than 300 hectares because the total probability (the sum of the probability of an event and its complement) equals 1.\n",
    "* If we were interested in seeing whether the reduction being less than 300, the answer would be given by `norm.cdf(300, mean_reduction, std_deviation)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b18d4e5",
   "metadata": {},
   "source": [
    "### Binomial distribution\n",
    "The Binomial distribution is a foundational concept in statistics, particularly useful in scenarios where we have a **series of independent experiments or trials** with two possible outcomes: **success** or **failure**. This distribution allows for the calculation of the probability of obtaining a specific number of successes in a fixed number of trials, assuming each trial is independent and the probability of success remains constant throughout the trials. \n",
    " \n",
    "Key properties of the Binomial distribution include;\n",
    "1. **Discreteness**: The Binomial distribution is discrete, meaning it calculates the probabilities of achieving a certain number of successes in a series of independent trials or events.\n",
    "2. **Fixed number of trials**: The total number of trials (n) is fixed in advance. Each trial is independent of the others, and the outcome of one trial does not affect the outcomes of the other trials.\n",
    "3. **Binary outcomes**: Each trial has only two possible outcomes, commonly referred to as \"success\" and \"failure\". The probability of success (p) is constant for each trial.\n",
    "4. **Probability of success**: The probability of success on a single trial is denoted by p, while the probability of failure is denoted by q, where q = 1 - p.\n",
    "5. **Sum of Bernoulli trials**: A Binomial distribution can be thought of as the sum of n independent Bernoulli trials, each with the same probability of success p.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd8dba",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/binomial-distribution.png\"  style=\"width:70%\";/>\n",
    "    <br>\n",
    "    <br>\n",
    "    <em>Figure 2: Binomial distribution</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009ffd4",
   "metadata": {},
   "source": [
    "**Mathematical representation**\n",
    "\n",
    "The probability of obtaining exactly k successes in n trials is given by the formula:\n",
    "\n",
    "$ P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k} $\n",
    "\n",
    "where:\n",
    "- $(P(X = k))$ is the probability of getting exactly k successes,\n",
    "- $(\\binom{n}{k})$ is the binomial coefficient, representing the number of ways to choose k successes from n trials,\n",
    "- $(p)$ is the probability of success on a single trial, and\n",
    "- $((1-p))$ is the probability of failure on a single trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41101e",
   "metadata": {},
   "source": [
    "Consider a conservation project monitoring the presence of a certain endangered species in a set of habitat areas. Each area is checked for the presence of the species, with each check considered an independent trial.\n",
    "\n",
    "- **n**: 50 habitat areas are surveyed.\n",
    "- **p**: The probability of finding the species in any given area is 0.2 (20%).\n",
    "\n",
    "Using the Binomial distribution, we can calculate the probability of finding the species in exactly 10 of the 50 areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "k = 10\n",
    "n = 50  # Number of trials\n",
    "p = 0.2  # Probability of success\n",
    "\n",
    "# Probability of exactly 10 successes (finding the species in 10 areas)\n",
    "prob_exactly_10 = binom.pmf(k, n, p)\n",
    "print(f\"Probability of finding the species in exactly 10 out of 50 areas: {prob_exactly_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91597ebd",
   "metadata": {},
   "source": [
    "This calculation helps in understanding the likelihood of various outcomes, aiding in the assessment of conservation efforts' effectiveness and the planning of future actions based on probabilistic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PMF \n",
    "n = 50\n",
    "x = np.arange(0,51)\n",
    "p1 = 0.2\n",
    "px1 = st.binom.pmf(x, n, p1)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(x, px1, 'k', label = 'p = 0.2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472ff49",
   "metadata": {},
   "source": [
    "### Poisson distribution\n",
    "\n",
    "The Poisson distribution is particularly useful for modelling the number of events occurring within a fixed interval of time or space when these events happen **independently** of each other at a **constant average rate**. It's an ideal tool for analysing count data where the events are discrete and the number of occurrences in any given interval can range from zero to potentially infinity. \n",
    "\n",
    "Key characteristics of the Poisson distribution include:\n",
    "\n",
    "1. **Events occur independently**: The occurrence of one event does not affect the probability of another event occurring.\n",
    "2. **Constant average rate**: Events occur at a constant mean rate ($\\lambda$) over time or space.\n",
    "3. **Discrete outcomes**: The number of events is counted in whole numbers.\n",
    "4. **Unbounded upper limit**: There's no maximum limit to the number of events that can occur in the given interval. (let n→∞ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a77ff0",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/poisson-distribution.png\"  style=\"width:70%\";/>\n",
    "    <br>\n",
    "    <br>\n",
    "    <em>Figure 3: Poisson distribution</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bdadaf",
   "metadata": {},
   "source": [
    "**Mathematical representation**\n",
    "\n",
    "The notation $X \\sim P(\\lambda)$ (that symbol $\\sim$ is read \"is distributed\") signifies that $X$ follows the Poisson distribution with parameter $\\lambda$.\n",
    "\n",
    "The probability of observing exactly \\(k\\) events in a fixed interval is given by the formula:\n",
    "\n",
    "$ P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $\n",
    "\n",
    "where:\n",
    "- $(P(X = k))$ is the probability of observing exactly \\(k\\) events,\n",
    "- $(\\lambda)$ is the average rate (mean) of events per interval,\n",
    "- $(e)$ is the base of the natural logarithm (approximately 2.71828),\n",
    "- $(k!)$ is the factorial of \\(k\\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c2039",
   "metadata": {},
   "source": [
    "Suppose an environmental agency has recorded an average rate $(\\lambda)$ of 5 illegal logging incidents per month in a particular region. We can use the Poisson distribution to calculate the probability of observing a specific number of incidents in a given month, which can inform enforcement and reforestation planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "lambda_illegal_logging = 5  # Average number of illegal logging incidents per month\n",
    "\n",
    "# Probability of observing exactly 3 illegal logging incidents in a month\n",
    "prob_exactly_3 = poisson.pmf(3, lambda_illegal_logging)\n",
    "print(f\"Probability of observing exactly 3 illegal logging incidents in a month: {prob_exactly_3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2349e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the PMF for this distribution\n",
    "poisson_lambda = 5\n",
    "x = np.arange(0,15)\n",
    "px = st.poisson.pmf(x, poisson_lambda)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,6)\n",
    "plt.plot(x, px, 'k', label = 'lambda = 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f702d53",
   "metadata": {},
   "source": [
    "Understanding the frequency of illegal logging incidents can help tailor reforestation efforts. For example, if the probability of a high number of incidents in certain months is significant, additional resources could be allocated for surveillance and reforestation during or following those periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of observing more than 7 illegal logging incidents in a month\n",
    "prob_more_than_7 = 1 - poisson.cdf(7, lambda_illegal_logging)\n",
    "print(f\"Probability of observing more than 7 illegal logging incidents in a month: {prob_more_than_7:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the cumulative density function for this distribution\n",
    "poisson_lambda = 5\n",
    "x = np.arange(0,15)\n",
    "px = st.poisson.cdf(x, poisson_lambda)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,6)\n",
    "plt.plot(x, px, 'k', label = 'lambda = 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b254284",
   "metadata": {},
   "source": [
    "This analysis assists in strategically planning reforestation projects, ensuring they are timed and resourced in a manner that accounts for the impact of illegal logging, thereby maximizing the success rate of reforestation efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27668c",
   "metadata": {},
   "source": [
    "### Negative binomial distribution\n",
    "\n",
    "Suppose once again that we have a binomial process, where each trial is either a success or a failure. If we let $X$ represent the number of **failures** that occur before we hit a specific number of **successes**, usually denoted $r$, and $p$ is the **probability of success** on each trial, then $X \\sim NB(r,p)$, i.e. $X$ follows the negative binomial distribution with parameters $r$ and $p$ and has PMF:\n",
    "\n",
    "\\begin{align}\n",
    "p(x) & = \\binom{x+r-1}{x} p^r (1-p)^{x} & & \\text{for } x = 0, 1, \\ldots, n\\\\\n",
    "     & = 0 & & \\text{otherwise}\n",
    "\\end{align}\n",
    "\n",
    "This PMF can be derived in an approach that is similar to the one used for the binomial distribution. Intuitively, each possible path that takes us to $r$ successes and $x$ failures must have probability $p^r (1-p)^x$. How many such combinations are there? Well, remember first of all that by our definition, the last trial must have been a success, so in the previous $x+r-1$ trials we will have had $x$ failures. \n",
    "\n",
    "There are $\\binom{x+r-1}{x}$ ways of arranging these\n",
    "$x$ failures and $r-1$ successes.\n",
    "\n",
    "Let's plot the PMF for $p = 0.3$ and $r$ equal to either 2 or 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMF for negative binomial distribution\n",
    "p = 0.3\n",
    "x = np.arange(0,11)\n",
    "r1 = 2\n",
    "px1 = st.nbinom.pmf(x, r1, p)\n",
    "r2 = 3\n",
    "px2 = st.nbinom.pmf(x, r2, p)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(x, px1, 'k', label = 'p = 0.3, r = 2')\n",
    "plt.plot(x, px2, 'r', label = 'p = 0.3, r = 3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951fb24",
   "metadata": {},
   "source": [
    "### Exponential distribution\n",
    "\n",
    "The exponential distribution is related to the Poisson process which underlies the Poisson distribution (a Poisson process is simply one in which events occur at the rate of $\\lambda$ per time period). \n",
    "\n",
    "Here, instead of modeling the number of events in a **time period**, as we did with the Poisson, we are interested in the **time interval** between events. Unlike the Poisson distribution, therefore, this is a **continuous random** variable. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Mathematical Representation**\n",
    "\n",
    "With $\\lambda$ defined as before, then the PDF for $X \\sim E(\\lambda)$ measuring the time between events is:\n",
    "\n",
    "\\begin{align}\n",
    "f(x) & = \\lambda e^{-\\lambda x}  & & \\text{for } x \\ge 0 \\\\\n",
    "     & = 0 & & \\text{otherwise}\n",
    "\\end{align}\n",
    "\n",
    "for $(x \\geq 0)$, where $(\\lambda)$ is the rate parameter, and $(e)$ is the base of the natural logarithm.\n",
    "\n",
    "\n",
    "The exponential distribution is a crucial statistical tool for modeling the time between occurrences in continuous time processes, especially when these events happen independently and at a constant average rate. \n",
    "\n",
    "Key features of the Exponential distribution include:\n",
    "1. **Memorylessness**: One of the unique properties of the Exponential distribution is its *memoryless* nature. This means that the probability of an event occurring in the future is independent of how much time has already elapsed.\n",
    "2. **Continuous Time**: Unlike the Poisson distribution, which counts occurrences in fixed intervals, the Exponential distribution deals with the time between these occurrences in a continuous space.\n",
    "3. **Rate Parameter ($\\lambda$)**: The rate at which events occur (average number of events in a time unit) is the inverse of the mean time between events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f66bf",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/exponential-distribution.png\"  style=\"width:70%\";/>\n",
    "    <br>\n",
    "    <br>\n",
    "    <em>Figure 4: Exponential distribution</em>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7878b5",
   "metadata": {},
   "source": [
    "Suppose a specific region is prone to forest fires, with an average occurrence **rate of 0.1** per year (or one fire every 10 years, on average). We can use the Exponential distribution to calculate the **probability** of the next fire occurring within a certain timeframe, **say the next 5 years,** which is crucial for planning reforestation and preventive measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21371723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "# Average time between forest fires is 10 years, so the rate λ = 0.1 per year\n",
    "lambda_fire = 0.1\n",
    "scale_fire = 1 / lambda_fire  # Scale parameter for the Exponential distribution is the inverse of λ\n",
    "\n",
    "# Probability of a forest fire occurring within the next 5 years\n",
    "prob_within_5_years_fire = expon.cdf(5, scale=scale_fire)\n",
    "print(f\"Probability of a forest fire occurring within the next 5 years: {prob_within_5_years_fire:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64642fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cdf for the exponential distribution\n",
    "lambda_var = 0.1\n",
    "x = np.arange(0,11,0.01)\n",
    "dx = st.expon.cdf(x, scale = 1/lambda_var)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(x, dx, 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f88285",
   "metadata": {},
   "source": [
    "Understanding the likelihood of forest fires (or other natural disasters) within a specific timeframe allows environmental planners to allocate resources more effectively. For example, if the probability of a fire occurring in the next five years is high, efforts can be focused on fire prevention measures, creating firebreaks, and selecting fire-resistant plant species for reforestation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b57ed",
   "metadata": {},
   "source": [
    "### Uniform distribution\n",
    "\n",
    "As the name suggests, a uniformly distributed random variable will take on any value in a given interval with equal probability. The two key parameters are therefore the lower and upper points of the interval, usually denoted $a$ and $b$ respectively, and $X \\sim U(a,b)$ has PDF:\n",
    "\n",
    "\\begin{align}\n",
    "f(x) & = \\displaystyle \\frac{1}{b-a} & & \\text{for } a \\le x \\le b \\\\\n",
    "     & = 0 & & \\text{otherwise}\n",
    "\\end{align}\n",
    "\n",
    "This looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 5\n",
    "\n",
    "x = np.linspace(a-1, b+1, 100)\n",
    "y = st.uniform.pdf(x, loc=a, scale=b-a)\n",
    "\n",
    "plt.plot(x, y, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acc38b",
   "metadata": {},
   "source": [
    "\n",
    "An integration exercise will show that the probability of an observation between $c$ and $d$, where $a < c < d < b$, is equal to $\\displaystyle \\frac{d - c}{b - a}$, which is intuitively correct given that the essence of a uniform distribution is that every possible observation between the lower and upper bounds is equally likely. Let's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adccf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 5\n",
    "c = 2\n",
    "d = 3\n",
    "\n",
    "st.uniform.cdf(d, loc = a, scale =  b-a) - st.uniform.cdf(c, loc = a, scale = b-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07493c0e",
   "metadata": {},
   "source": [
    "Note: The 0.19999 instead of 0.2 answer is an example of Python's [floating point precision](https://docs.python.org/3/tutorial/floatingpoint.html) limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badb9fd",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "* [An Introduction to the Science of Statistics](https://www.math.arizona.edu/~jwatkins/statbook.pdf)\n",
    "* [Statistics and machine learning](https://towardsdatascience.com/machine-learning-probability-statistics-f830f8c09326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6db51",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
