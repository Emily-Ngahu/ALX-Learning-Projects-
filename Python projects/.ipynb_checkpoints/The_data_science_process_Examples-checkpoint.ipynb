{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: The Data Science Process\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore the fundamental concepts of Univariate and Multivariate Analysis, focusing on the crucial stages of the Data Science Process. We delve into various techniques of Exploratory Data Analysis (EDA), both graphical and non-graphical, to uncover patterns and relationships within the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "In this train we will learn:\n",
    "- Understand the key stages of the Data Science Process and how to use it when solving problems.\n",
    "- Know how to collect, clean, and analyse data using both Univariate and Multivariate Analysis techniques.\n",
    "- Know how to apply various graphical and non-graphical methods to extract insights and identify trends.\n",
    "- Know how to interpret and communicate the results of data analysis clearly, understanding the importance of each step in making informed decisions and building robust data models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "You will learn about the **data science process**, also known as a project life cycle, in this train. You should follow this process every time you start a new data science project. Once you are familiar with the different phases of the data science process, we will hone in on one of the phases, exploring the data, and learn about **exploratory data analysis (EDA)** and the different **types** of EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sm6oc90_x5y-"
   },
   "source": [
    "## Data Science Process\n",
    "\n",
    "When you are given a data science problem to solve, the question is always: Where do I start? \n",
    "Although every problem is unique, the process we follow is not. \n",
    "The data science process is a framework we can follow to solve any data science problem.\n",
    " \n",
    "The data science process consists of the following **five phases**:\n",
    "\n",
    "<div align=\"center\" style=\"width: 500px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/50f8665f1ecb715e39051574ad5f6ba8f7bbb3f2/regression_analysis_notebook/data_science_process.jpg?raw=True\"\n",
    "     alt=\"Dummy image 1\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=500px/>\n",
    "     A Visual Guide to Standard Procedures in Data Science <a href=\"https://towardsdatascience.com/the-data-science-process-a19eb7ebc41b\">here</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1:  Data Collection\n",
    "\n",
    "Data is required to help you find a solution to your data science problem. The data will provide insights that will lead you to a solution. Your data can be collected in many different ways. A company might store their data on internal databases that you need to query, or you might need to request external datasets that can be given to you in a CSV file. \n",
    "\n",
    "### Phase 2:  Data Cleaning\n",
    "\n",
    "Before doing any analysis on your data for insights, it is essential to clean the data first. Cleaning the data will ensure that you get accurate insights in the analysis phase. Cleaning your data will consist of checking for null, empty, missing and duplicated values. \n",
    "\n",
    "### Phase 3:  Exploratory Data Analysis\n",
    "\n",
    "This phase is extremely important. It helps us to understand patterns in our data, pinpoint any outliers and indicate relationships between variables. This phase includes descriptive statistics and data visualisations.\n",
    "\n",
    "### Phase 4:  Model Building\n",
    "\n",
    "In this phase, you need to select the features (variables) that will contribute to your model.  Not all features will be relevant. You will now be able to build a regression or classification model; this will include applying multiple algorithms to get the best model. Once we have decided on the best algorithm, we will train our model on the input data.\n",
    "\n",
    "Data Modelling will only be successful and make sense if you have performed data cleaning and exploratory analysis. \n",
    "\n",
    "\n",
    "### Phase 5: Model Deployment\n",
    "\n",
    "Model deployment is taking your trained model from phase 4 and making it available in a production environment. Deploying your model will make your model’s predictions on incoming data available to users or other systems.  \n",
    "\n",
    "An example of this would be Netflix making recommendations; this is based on the Netflix machine learning model using your streaming data to make predictions on what you would like to watch next. \n",
    "\n",
    "This phase is also commonly known as:  *Where the magic happens!*\n",
    "<div align=\"center\" style=\"width: 90px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/magic.png?raw=True\"\n",
    "     alt=\"Magic\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=90px/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bv12xz-ZjaLD"
   },
   "source": [
    "\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "### Why is EDA important?\n",
    "\n",
    "Exploratory Data Analysis (EDA) helps us to understand our data without making any assumptions. EDA is a vital component before we continue with the modelling phase as it provides context and guidance on the course of action to take when developing the appropriate model. It will also assist in interpreting the results correctly. Without doing EDA you will not understand your data fully.\n",
    "\n",
    "\n",
    "### The different types of EDA\n",
    "\n",
    "EDA are generally classified in two ways:\n",
    "\n",
    "    1) Non-graphical or Graphical\n",
    "    2) Univariate or Multivariate\n",
    "    \n",
    "<div align=\"left\" style=\"width: 600px; text-align: left;\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f860f39251c523eda779dea0140316ccbefdd8e0/eda_map.jpg?raw=True\"\n",
    "     alt=\"EDA Diagram\"\n",
    "     style=\"padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Non-graphical EDA\n",
    "Involves calculations of summary/descriptive statistics. \n",
    "\n",
    "#### Graphical EDA\n",
    "This type of analysis will contain data visualisations.\n",
    "\n",
    "#### Univariate Analysis \n",
    "This is performed on one variable at a time as the prefix 'uni' indicates. \n",
    "\n",
    "#### Multivariate Analysis \n",
    "This type of analysis explores the relationship between two or more variables. \n",
    "When only comparing two variables it is known as **bivariate analysis** as indicated by the prefix 'bi'.\n",
    "\n",
    "Read a more detailed explanation <a href=\"https://www.stat.cmu.edu/~hseltman/309/Book/chapter4.pdf\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "### Example 1\n",
    "\n",
    "For a practical example, we will be looking at the Medical Claims Data. Using these four commands, we will perform a basic analysis:\n",
    "\n",
    "    - df.head()\n",
    "    - df.shape\n",
    "    - df.info()\n",
    "    - df.describe()\n",
    "    \n",
    "First, we'll import the libraries we will need, followed by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/claims_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>steps</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>insurance_claim</th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>3009</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>3008</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>yes</td>\n",
       "      <td>1725.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3009</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>8010</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>yes</td>\n",
       "      <td>3866.8552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  steps  children smoker     region insurance_claim  \\\n",
       "0   19  female  27.900   3009         0    yes  southwest             yes   \n",
       "1   18    male  33.770   3008         1     no  southeast             yes   \n",
       "2   28    male  33.000   3009         3     no  southeast              no   \n",
       "3   33    male  22.705  10009         0     no  northwest              no   \n",
       "4   32    male  28.880   8010         0     no  northwest             yes   \n",
       "\n",
       "   claim_amount  \n",
       "0    16884.9240  \n",
       "1     1725.5523  \n",
       "2        0.0000  \n",
       "3        0.0000  \n",
       "4     3866.8552  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top five rows of our data we can see all our features as well as the types of data we are working with.\n",
    "\n",
    "Our features are:\n",
    "\n",
    "    - age\n",
    "    - sex\n",
    "    - bmi\n",
    "    - steps\n",
    "    - children\n",
    "    - smoker\n",
    "    - region\n",
    "    - insurance_claim\n",
    "    - claim_amount\n",
    "\n",
    "The types of visualisations we can create differ depending on the data type of each variable. Broadly, we need to determine whether a variable is numerical, or categorical. Currently, the `categorical` features are `sex`, `smoker`, `region` and `insurance_claim`. The `numerical` features are `age`, `bmi`, `steps`, `children` and `claim_amount`. This is confirmed by looking specifically at the data type of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape command shows us that we have **1338** rows of data and **9** features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info command confirms our categorical and numerical features. If a feature (variable) is categorical the Dtype is **object** and if it is a numerical variable the Dtype is an **int64** or **float64**. This command also shows us that out of the 1338 none of the features contain any null values.\n",
    "\n",
    "Null values for each feature can also be checked by using the following command:\n",
    "\n",
    "    - df.isnull().sum()\n",
    "    \n",
    "This command will provide the total number of null values appearing in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that there are no null values in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "The first univariate analysis will be non-graphical. This is where we will be looking at the **descriptive statistics** of each feature. We can get the descriptive statistics of each numerical feature by using the following command:\n",
    "\n",
    "    - df.describe()\n",
    "\n",
    "This command will provide the mean, standard deviation and a five number summary of each numerical feature.\n",
    "The five number summary (Minimum, Lower Quartile (Q1) = 25%, Median (Q2) = 50%, Upper Quartile (Q3) = 75%, Maximum) is also used for creating the box plot.\n",
    "\n",
    "Individual statistical measures can also be calculated by using the following commands:\n",
    "\n",
    "    - df.count()\n",
    "    - df.mean()\n",
    "    - df.std()\n",
    "    - df.min()\n",
    "    - df.quantile([0.25, 0.5, 0.75], axis = 0)\n",
    "    - df.median()\n",
    "    - df.max()\n",
    "\n",
    "The three measures for central tendency are the mode, mean and median. The command to determine the mode is:\n",
    "\n",
    "    - df.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the statistics of a specific feature by using the same command and specifying the column.\n",
    "\n",
    "    - df.age.describe() or df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional statistical measures that can be calculated are **kurtosis** and **skew**. \n",
    "\n",
    "Both kurtosis and skew are important statistical terms to be familiar with in data science. Kurtosis is the measure of outliers present in the data. **High kurtosis (>3)** indicates a large number of outliers and **low kurtosis (<3)** a lack of outliers.  Skew will indicate how symmetrical your data is. Below is a table that explains the range of values with regards to skew.\n",
    "\n",
    "\n",
    "|   Skew Value (x)  |       Description of Data      |\n",
    "|:-------------------|:---------------:|\n",
    "| -0.5 < x < 0.5              |Fairly Symmetrical |\n",
    "| -1 < x < -0.5 | Moderate Negative Skew  | \n",
    "| 0.5 < x < 1             | Moderate Positive Skew  | \n",
    "|       x < -1     |High Negative Skew  | \n",
    "|       x > 1  |High Positve Skew | \n",
    "\n",
    "<div align=\"left\" style=\"width: 500px; font-size: 80%; text-align: left; margin: 0 auto\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/skew.jpg?raw=True\"\n",
    "     alt=\"Dummy image 1\"\n",
    "     style=\"float: left; padding-bottom=0.5em\"\n",
    "     width=500px/>\n",
    "     For a more detailed explanation on skew and kurtosis read <a href=\"https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa\">here</a>.\n",
    "</div>\n",
    "\n",
    "\n",
    "The commands used to determine the skew and kurtosis of data are:\n",
    "\n",
    "    - df.skew()\n",
    "    - df.kurtosis()\n",
    "\n",
    "    Note: These functions can only operate on numerical data so we use `numeric_only=True` to automatically ignore non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew(numeric_only=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features `age` and `bmi` are fairly symmetrical; `steps` and `children` are moderately skewed in a positive direction, and `claim_amount` is the only feature that is highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.kurtosis(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicates a lack of outliers for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "Now let's conduct a univariate analysis using graphical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at the **distribution** of any numerical feature by using the following plots:\n",
    "\n",
    "    - histogram\n",
    "    - density plot\n",
    "    - box plot\n",
    "    - violin plot\n",
    "    \n",
    "For a categorical feature we will use a:\n",
    "\n",
    "    - bar plot\n",
    "\n",
    "#### Histogram and Density Plot\n",
    "\n",
    "For displaying a histogram and density plot we will be using the Matplotlib library and create a list of all numerical features to visualise these features at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'bmi', 'steps', 'children', 'claim_amount'] # create a list of all numerical features\n",
    "df[features].hist(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features].plot(kind='density', subplots=True, layout=(3, 2), sharex=False, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that both the histogram and density plot display the same information. The density plot can be considered a smoothed version of the histogram and does not depend on the size of bins.\n",
    "\n",
    "#### Box Plot and Violin Plot\n",
    "\n",
    "For the Box Plot and Violin Plot, we will use the seaborn library and only select one feature instead of all the numerical features. We can visualise all numerical features simultaneously, but as the range of values for each feature is different, it will not create a useful visualisation. Standardisation or normalisation can be applied to a feature to adjust the range, but we will not apply it in this notebook. Further reading on standardisation and normalisation can be done <a href=\"https://medium.com/@dataakkadian/standardization-vs-normalization-da7a3a308c64\">here</a>.\n",
    "\n",
    "The `bmi` feature will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='bmi', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='bmi', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both the box plot and violin plot display the distribution of the data, the boxplot provides certain statistics that are useful. \n",
    "\n",
    "The five vertical lines in the boxplot provide the information of the five number summary and the dots on the right hand side of the graph is a display of outliers. The violin plot focuses more on a smoothed distribution.\n",
    "\n",
    "#### Bar Plot\n",
    "\n",
    "For the categorical features, we can create a **bar plot** to display the frequency distribution. \n",
    "\n",
    "We'll generate a bar plot of the `children` feature, where each bar represents a unique number of children from the data, and the height represents how many times that number of children occurred. This can be done by using seaborn's `countplot`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'children', data = df, palette=\"hls\")\n",
    "plt.title(\"Distribution of Children\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "Let's conduct a non-graphical multivariate analysis.\n",
    "\n",
    "For this analysis, we can determine the relationship between any two numerical features by calculating the correlation coefficient. Correlation is a measure of the degree to which two variables change together, if at all. If two features have a strong positive correlation, it means that if the value of one feature increases, the value of the other feature also increases. There are three different correlation measures:\n",
    "\n",
    "    - Pearson correlation \n",
    "    - Spearman rank correlation\n",
    "    - Kendall correlation\n",
    "\n",
    "For this lesson, we will focus on the Pearson correlation. The Pearson correlation measures the linear relationship between features and assumes that the features are normally distributed. Below is a table that explains how to interpret the Pearson correlation measure:\n",
    "\n",
    "\n",
    "|   Pearson Correlation Coefficient (r)  |       Description of Relationship     |\n",
    "|:-------------------|:---------------:|\n",
    "|  r = -1              |Perfect Negative Correlation |\n",
    "| -1 < r < -0.8 | Strong Negative Correlation  | \n",
    "| - 0.8 < r < -0.5             | Moderate Negative Correlation  | \n",
    "|       - 0.5 < r < 0     |Weak Negative Correlation  | \n",
    "|       r = 0  |No Linear Correlation | \n",
    "| 0 < r < 0.5 | Weak Positive Correlation  | \n",
    "| 0.5 < r < 0.8             | Moderate Positive Correlation  | \n",
    "|       0.8 < r < 1     |Strong Positive Correlation  | \n",
    "|       r = 1  |Perfect Positive Correlation | \n",
    "\n",
    "\n",
    "<div align=\"left\" style=\"width: 800px; text-align: left;\">\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/f3aeedd2c056ddd233301c7186063618c1041140/regression_analysis_notebook/pearson_corr.jpg?raw=True\"\n",
    "     alt=\"Pearson Correlation\"\n",
    "     style=\"padding-bottom=0.5em\"\n",
    "     width=800px/>\n",
    "</div>\n",
    "\n",
    "For a more detailed explanation of correlations, read <a href=\"https://medium.com/fintechexplained/did-you-know-the-importance-of-finding-correlations-in-data-science-1fa3943debc2#:~:text=Correlation%20is%20a%20statistical%20measure,to%20forecast%20our%20target%20variable.&text=It%20means%20that%20when%20the,variable(s)%20also%20increases.\">here</a>.\n",
    "\n",
    "The command we will use to determine the correlation between features is:\n",
    "\n",
    "    - df.corr()\n",
    "\n",
    "Note: This function can only operate on numerical data so we use `numeric_only=True` to automatically ignore non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at a two of the correlations between different features:\n",
    "\n",
    "    - age & bmi = weak positive correlation\n",
    "    - steps & bmi = moderate negative correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5\n",
    "\n",
    "Now, let's use graphical methods to conduct a multivariate analysis.\n",
    "\n",
    "For the multivariate graphical analysis the following visualisations will be considered:\n",
    "\n",
    "    - Heatmap\n",
    "    - Scatter Plot\n",
    "    - Pair Plot\n",
    "    - Joint Plot\n",
    "    - Bubble Plot\n",
    "    \n",
    "#### Heatmap\n",
    "\n",
    "The relationship between features can also be displayed graphically using a **heatmap**. The Seaborn library will be used for this basic heatmap visualisation. \n",
    "\n",
    "To see how different heatmap variations can be created, read <a href=\"https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\">here</a>.\n",
    "\n",
    "The correlation coefficient value will be displayed on the heatmap using the `vmin` and `vmax` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(df.corr(numeric_only=True), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plot\n",
    "\n",
    "A Scatter plot is used to visualise the relationship between two different features and is most likely the primary multivariate graphical method. For this exercise, we will create a scatter plot to determine if there is a relationship between `bmi` and `age`. The parameter `hue` is set to the feature `insurance_claim`, colouring the points according to whether or not a claim was submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age',y='bmi',hue='insurance_claim', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated by the low correlation coefficient value of 0.11 and now the scatterplot, there is a very weak relationship between bmi and age.\n",
    "\n",
    "#### Pair Plot\n",
    "\n",
    "A pair plot can be used to visualise the relationships between all the numerical features at the same time. The `hue` is once again set to the feature `insurance_claim` to indicate which data points submitted an insurance claim and which didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\");\n",
    "sns.pairplot(df, hue=\"insurance_claim\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint Plot\n",
    "\n",
    "The joint plot can be used to provide univariate and multivariate analyses at the same time. The central part of the plot will be a scatter plot comparing two different features. The top and right visualisations will display the distribution of each feature as a histogram. \n",
    "\n",
    "For this joint plot, we will once again compare `age` and `bmi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'age', y = 'bmi', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualisation can be changed slightly by including the `hue` as `insurance_claim` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x = 'age', y = 'bmi', data = df, hue='insurance_claim');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bubble Plots\n",
    "\n",
    "A bubble plot is a variation of a scatter plot. Bubbles vary in size, dependent on another feature in the data. The same applies to the colour of the bubbles; which can be set to vary with the values of another feature. This way, we can visualise up to four dimensions/features at the same time.\n",
    "\n",
    "For this bubble plot, `bmi` and `claim_amount` will be plotted on the x-axis and y-axis, respectively. The colours of the bubbles will vary based on whether the observation is a `smoker` or not, and lastly, the size of the bubbles will vary based on the number of `children` the observation has. We will create this bubble plot by using `seaborn`’s scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=\"bmi\", \n",
    "                y=\"claim_amount\",\n",
    "                size=\"children\",\n",
    "                sizes=(20,100),\n",
    "                alpha=0.8,\n",
    "                hue=\"smoker\",\n",
    "                data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bubble plot indicates that claimants who are smokers (blue) and have higher BMIs (further right) tend to make larger insurance claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided an introductory lesson to three fundamental aspects.\n",
    "\n",
    "#### The Data Science Process\n",
    "Following the data science process is crucial for producing reliable, repeatable work. The phases are:\n",
    "- Collecting;\n",
    "- Cleaning;\n",
    "- Exploratory data analysis;\n",
    "- Model building; and\n",
    "- Model deployment.\n",
    "\n",
    "Each of these phases is integral to the data science process and should receive the required attention.\n",
    "\n",
    "#### Exploratory Data Analysis (EDA)\n",
    "Understanding the importance of exploratory data analysis and making it part of every data science project you do will make the feature and algorithm selection of phase 4 of the data science process much more manageable. It gives you a vital understanding of your data which is extremely important for building and selecting the best algorithm for your model.\n",
    "\n",
    "#### The different types of EDA\n",
    "We first break exploratory data analysis down into non-graphical and graphical analysis and then univariate and multivariate analysis. Non-graphical analysis is done by using descriptive statistics, whereas graphical analysis is done by using visualisations. In this notebook, we use the `seaborn` and `matplotlib` libraries to create visualisations, but various other tools exist for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources \n",
    "\n",
    "Reference these articles and notebooks for more information on this topic:\n",
    "\n",
    " - [Multivariate plotting](https://www.kaggle.com/residentmario/multivariate-plotting)\n",
    " - [Extensive Analysis + Visualisation with Python](https://www.kaggle.com/prashant111/extensive-analysis-visualization-with-python)\n",
    " - [Data Visualisation using matplotlib and seaborn](https://aaaanchakure.medium.com/data-visualization-a6dccf643fbb)\n",
    " - [Dramatically Improve Your Exploratory Data Analysis (EDA)](https://towardsdatascience.com/dramatically-improve-your-exploratory-data-analysis-eda-a2fc8c851124)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "12_kmeans_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
