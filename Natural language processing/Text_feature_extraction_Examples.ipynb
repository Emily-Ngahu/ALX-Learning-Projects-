{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpIPMNPoU_-p"
   },
   "source": [
    "# Examples: Text feature extraction\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will delve into text feature extraction techniques, focusing on the bag-of-words model and n-grams. We'll explore how to transform text data into feature sets usable by classifiers, particularly using the NLTK library. The bag-of-words model simplifies text into word presence features, while n-grams capture combinations of words to extract deeper meaning from text. \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "* Understand the bag-of-words model and its role in text feature extraction.\n",
    "* Implement the bag-of-words model to transform text data into feature sets.\n",
    "* Explain the concept of n-grams and their significance in capturing combinations of words.\n",
    "* Use n-grams to extract contextual information from text data.\n",
    "* Fine-tune CountVectorizer parameters for optimal text feature extraction.\n",
    "\n",
    "\n",
    "Before we get started, let's get the data and the  libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "# Set the path to the CA certificates bundle\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQm0O5XHU_-z",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "import string\n",
    "\n",
    "# set plot style\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29356,
     "status": "error",
     "timestamp": 1560340175121,
     "user": {
      "displayName": "Bryan Davies",
      "photoUrl": "",
      "userId": "03059035420523728518"
     },
     "user_tz": -120
    },
    "id": "w8Iw1yCRU_-2",
    "outputId": "188501d1-fcf6-45be-8a45-56f885491dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n",
    "# or you can download directly, i.e.\n",
    "nltk.download(['punkt','stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with our `MBTI` dataset, let's read the data and clean it up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the MBTI dataset\n",
    "mbti = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint/mbti_train.csv')\n",
    "mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://41.media.tumblr.com/tumblr_lfouy03PMA1q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  https://www.youtube.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>http://www.youtube.com/watch?v=vXZeYwwRDw8   h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316543</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Kallinhausin, you may have just rooted out the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316544</th>\n",
       "      <td>INFP</td>\n",
       "      <td>In regards to the king, (in the show, not in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316545</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Sunlight bouncing off the fog at dawn.  Serend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316546</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Songs are really powerful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316547</th>\n",
       "      <td>INFP</td>\n",
       "      <td>I just have to remember they weren't trying to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                               post\n",
       "0       INFJ        'http://www.youtube.com/watch?v=qsXHcwe3krw\n",
       "1       INFJ  http://41.media.tumblr.com/tumblr_lfouy03PMA1q...\n",
       "2       INFJ  enfp and intj moments  https://www.youtube.com...\n",
       "3       INFJ  What has been the most life-changing experienc...\n",
       "4       INFJ  http://www.youtube.com/watch?v=vXZeYwwRDw8   h...\n",
       "...      ...                                                ...\n",
       "316543  INFP  Kallinhausin, you may have just rooted out the...\n",
       "316544  INFP  In regards to the king, (in the show, not in t...\n",
       "316545  INFP  Sunlight bouncing off the fog at dawn.  Serend...\n",
       "316546  INFP                         Songs are really powerful.\n",
       "316547  INFP  I just have to remember they weren't trying to...\n",
       "\n",
       "[316548 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate each post in the 'posts' column into its own row\n",
    "all_mbti = []\n",
    "for i, row in mbti.iterrows():\n",
    "    for post in row['posts'].split('|||'):\n",
    "        all_mbti.append([row['type'], post])\n",
    "all_mbti = pd.DataFrame(all_mbti, columns=['type', 'post'])\n",
    "\n",
    "all_mbti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove noise\n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'\n",
    "all_mbti['post'] = all_mbti['post'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "all_mbti['post'] = all_mbti['post'].str.lower()\n",
    "\n",
    "#Remove puntuation\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])\n",
    "\n",
    "all_mbti['post'] = all_mbti['post'].apply(remove_punctuation)\n",
    "\n",
    "# Tokenize the text using the TreebankWordTokenizer\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "all_mbti['tokens'] = all_mbti['post'].apply(tokeniser.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>urlweb</td>\n",
       "      <td>[urlweb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>urlweb</td>\n",
       "      <td>[urlweb]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  urlweb  sportscenter no...</td>\n",
       "      <td>[enfp, and, intj, moments, urlweb, sportscente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>what has been the most lifechanging experience...</td>\n",
       "      <td>[what, has, been, the, most, lifechanging, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>urlweb   urlweb  on repeat for most of today</td>\n",
       "      <td>[urlweb, urlweb, on, repeat, for, most, of, to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post  \\\n",
       "0  INFJ                                             urlweb   \n",
       "1  INFJ                                             urlweb   \n",
       "2  INFJ  enfp and intj moments  urlweb  sportscenter no...   \n",
       "3  INFJ  what has been the most lifechanging experience...   \n",
       "4  INFJ       urlweb   urlweb  on repeat for most of today   \n",
       "\n",
       "                                              tokens  \n",
       "0                                           [urlweb]  \n",
       "1                                           [urlweb]  \n",
       "2  [enfp, and, intj, moments, urlweb, sportscente...  \n",
       "3  [what, has, been, the, most, lifechanging, exp...  \n",
       "4  [urlweb, urlweb, on, repeat, for, most, of, to...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text feature extraction\n",
    "\n",
    "### Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbRb9FHYVAAg"
   },
   "source": [
    "Text feature extraction is the process of transforming what is essentially a list of words into a feature set that is usable by a classifier. The NLTK classifiers expect `dict` style feature sets, so we must therefore transform our text into a Python dictionary object. The Bag of Words model is the simplest method; it constructs a word presence feature set from all the words in the text, indicating the number of times each word has appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mg8PtprJVAAg",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\" this function takes in a list of words and returns a dictionary \n",
    "        with each word as a key, and the value represents the number of \n",
    "        times that word appeared\"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a set of dictionaries, one for each of the MBTI types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of all the MBTI personality types that are present in the original dataset\n",
    "type_labels = list(all_mbti.type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtqJO_YhVAAh",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "personality = {}\n",
    "for pp in type_labels:\n",
    "    df = all_mbti.groupby('type')\n",
    "    personality[pp] = {}\n",
    "    for row in df.get_group(pp)['tokens']:\n",
    "        personality[pp] = bag_of_words_count(row, personality[pp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list of all of the unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ky-rofa_VAAi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_words = set()\n",
    "for pp in type_labels:\n",
    "    for word in personality[pp]:\n",
    "        all_words.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was done so that we can create a combined bag of words dictionary for all the words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpjTsIOsVAAl",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "personality['all'] = {}\n",
    "for pp in type_labels:    \n",
    "    for word in all_words:\n",
    "        if word in personality[pp].keys():\n",
    "            if word in personality['all']:\n",
    "                personality['all'][word] += personality[pp][word]\n",
    "            else:\n",
    "                personality['all'][word] = personality[pp][word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily calculate how many words there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUGBaAELVAAp",
    "outputId": "beff7596-19e4-43bb-ecce-291231be4c21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8203466"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = sum([v for v in personality['all'].values()])\n",
    "total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of words which occur less than 10 times in the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiSrw4V3VAAn",
    "outputId": "b59469fe-8252-4546-94b3-76c1d9ac59bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'word frequency')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAG1CAYAAAA2g8rpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGZklEQVR4nO3deXhU9dn/8c9MdhIGQ4QEQbZgCMgWSEJSBQJS2iK2jVipEhUkSgUFRAQVZBWlEhbZRTatUIEGUR9UKFRrsSQk1uWnISLrAzYLS0gCZCEz8/uDJ9NMcckJEyYzvl/XletKzvmee+57QPLxnDMzJrvdbhcAAABqzezuBgAAADwNAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgkK+7G/BWdrtdNlv9vMm72Wyqt9oNgbfPJ3n/jMzn+bx9RubzfPUxo9lskslkqtVaAlQ9sdnsOnv2gsvr+vqaFRoarJKSi6qqsrm8vrt5+3yS98/IfJ7P22dkPs9XXzM2bRosH5/aBSgu4QEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAg3zd3QDqxsfHs7KvzWaXzWZ3dxsAALgEAcrDmEwm2Wx2WSxB7m7FEKvVpnPnLhKiAABewe0BqqqqSsuXL9f27dt17tw5de7cWU8++aR69OghSTpw4IDmzp2rL7/8Uk2bNtWIESN0//33O4632WxatmyZtm7dqtLSUsXFxWn69Om68cYbHWtcUaOhMJtNMptNStv4iU4WlLq7nVppFd5Yk4b3ktlsIkABALyC2wPUypUrtXXrVs2bN0833nijXnnlFaWmpurdd9+Vn5+fRo4cqQEDBmjWrFn67LPPNGvWLAUHB2vo0KGSpBUrVmjTpk2aN2+eIiIiNH/+fKWmpuqdd96Rv7+/ioqKrrpGQ3SyoFSHvy12dxsAAPwkuf1Gmt27d2vIkCG69dZb1aZNGz311FMqLS3VZ599pi1btsjPz0+zZ89WZGSkhg4dqhEjRmj16tWSpMrKSq1bt07jxo1TUlKSoqOjtWjRIuXn52vXrl2S5JIaAAAANbk9QIWFhemDDz7QyZMnZbVatXnzZvn7+ys6OlrZ2dmKj4+Xr+9/TpQlJCTo2LFjOn36tHJzc3XhwgUlJiY69lssFnXu3FlZWVmS5JIaAAAANbn9Et7UqVM1fvx43XbbbfLx8ZHZbNbSpUvVunVr5efnKyoqyml98+bNJUl5eXnKz8+XJLVo0eKKNdX7XFGjrnx9XZ9PzWaTy2teK7V55WD1Gk97laER3j4j83k+b5+R+TxfQ5jR7QHq0KFDaty4sZYvX67w8HBt3bpVkyZN0uuvv67y8vIr7kEKCAiQJFVUVKisrEySvnNNcfHl+4NcUaMuzGaTQkOD63y8NzLyykFPe5VhXXj7jMzn+bx9RubzfO6c0a0BKi8vT0888YQ2bNig2NhYSVLXrl116NAhLV26VIGBgaqsrHQ6pqKiQpLUqFEjBQYGSrp8H1P199VrgoIuP6muqFEXNptdJSUX63z89/Hz81FISOCPL2yASkrKZLXafnCNj49ZFktQrdZ6Km+fkfk8n7fPyHyer75mtFiCan1Wy60B6vPPP9elS5fUtWtXp+3du3fXRx99pBtuuEGFhYVO+6p/Dg8PV1VVlWNb69atndZ07NhRkhQREXHVNeqqqsr1f3E9+ZSs1Wqr9XNiZK2n8vYZmc/zefuMzOf53DmjW38bR0RESJK+/vprp+0HDx5U27ZtFRcXp08++URWq9WxLyMjQ+3atVNYWJiio6MVEhKizMxMx/6SkhLl5OQoLi5OklxSAwAAoCa3Bqhu3bqpV69emjJlijIyMnTs2DEtXrxY+/bt08MPP6yhQ4fq/Pnzmjp1qg4dOqRt27Zpw4YNGj16tKTL9y2lpKQoLS1Ne/bsUW5urh5//HFFRERo0KBBkuSSGgAAADW59RKe2WzWypUrtXjxYj399NMqLi5WVFSUNmzYoO7du0uS1qxZo7lz5yo5OVnNmjXT5MmTlZyc7Kgxbtw4VVVVadq0aSovL1dcXJzWrl0rPz8/SZffJuFqawAAANRkstvtfLZGPbBabTp79oLL6wYE+MpiCdKEhR96zDuRR7ZsosUTk1RUdOFHr1X7+poVGhpcq7WeyttnZD7P5+0zMp/nq68ZmzYNrvW9xp57RzIAAICbEKAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQW4NUJmZmerYseN3ft12222SpJMnT2r06NHq2bOnbr31Vi1evFhWq9WpzsaNG3XbbbepW7duuvfee5WTk+O03xU1AAAAqrk1QMXExGjv3r1OX8uWLZPJZNKYMWN06dIljRo1SpL0xhtvaObMmfrzn/+s5cuXO2q8+eabevHFFzV+/Hht27ZNrVq10siRI3X27FlJckkNAACAmtwaoPz9/dWsWTPHV3BwsF544QUlJydr6NCh2rlzp/7973/rxRdfVFRUlAYOHKiJEyfq1VdfVWVlpSRp1apVSklJ0a9//Wt16NBBzz//vIKCgrR161ZJckkNAACAmhrUPVCrVq1SWVmZpkyZIknKzs7WzTffrCZNmjjWJCQk6Pz58zpw4IDOnDmjY8eOKTEx0bHf19dXsbGxysrKclkNAACAmnzd3UC1s2fPasOGDXriiSd03XXXSZLy8/MVERHhtK558+aSpLy8PPn6Xm6/RYsWV6zJzc11WY268vV1fT41m00ur3mt+Pj8+PNRvaY2az2Vt8/IfJ7P22dkPs/XEGZsMAFq06ZNaty4sYYNG+bYVl5eLovF4rQuICBAklRRUaGysjJJly8F/veaiooKl9WoC7PZpNDQ4Dof740slqB6WeupvH1G5vN83j4j83k+d87YYALU9u3b9dvf/laBgYGObYGBgY77lKpVh5pGjRo51n7XmqCgIJfVqAubza6Skot1Pv77+Pn5KCQk8McXNkAlJWWyWm0/uMbHxyyLJahWaz2Vt8/IfJ7P22dkPs9XXzNaLEG1PqvVIAJUbm6uTpw4oTvuuMNpe0REhA4ePOi0rbCwUJIUHh7uuOxWWFioyMhIpzXh4eEuq1FXVVWu/4vryadkrVZbrZ8TI2s9lbfPyHyez9tnZD7P584ZG8Rv4+zsbIWFhSk6Otppe1xcnHJycnT+/HnHtoyMDAUHBys6OlphYWFq166dMjMzHfurqqqUnZ2tuLg4l9UAAACoqUEEqJycHHXs2PGK7QMHDlSzZs00YcIE5ebmavfu3Vq4cKEefPBBxz1LDz74oNavX68333xThw4d0jPPPKPy8nLdddddLqsBAABQU4O4hHfq1CnHK+9qCggI0Jo1azRr1izdfffdatKkie69916NGTPGsebuu+9WaWmpFi9erHPnzqlLly5av369mjZt6rIaAAAANZnsdrvd3U14I6vVprNnL7i8bkCAryyWIE1Y+KEOf1vs8vr1IbJlEy2emKSiogs/eq3a19es0NDgWq31VN4+I/N5Pm+fkfk8X33N2LRpcK3vNW4Ql/AAAAA8CQEKAADAIAIUAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGNQgAtT27ds1ePBgde3aVbfffrvee+89x76TJ09q9OjR6tmzp2699VYtXrxYVqvV6fiNGzfqtttuU7du3XTvvfcqJyfHab8ragAAAFRze4B66623NHXqVA0fPlw7duzQkCFDNHHiRH366ae6dOmSRo0aJUl64403NHPmTP35z3/W8uXLHce/+eabevHFFzV+/Hht27ZNrVq10siRI3X27FlJckkNAACAmtwaoOx2u1566SXdf//9Gj58uFq3bq1HHnlEP/vZz7R//37t3LlT//73v/Xiiy8qKipKAwcO1MSJE/Xqq6+qsrJSkrRq1SqlpKTo17/+tTp06KDnn39eQUFB2rp1qyS5pAYAAEBNbg1QR48e1bfffqs77rjDafvatWs1evRoZWdn6+abb1aTJk0c+xISEnT+/HkdOHBAZ86c0bFjx5SYmOjY7+vrq9jYWGVlZUmSS2oAAADU5OvOBz969Kgk6eLFixo1apRycnLUqlUrPfLIIxowYIDy8/MVERHhdEzz5s0lSXl5efL1vdx+ixYtrliTm5srSS6pUVe+vq7Pp2azyeU1rxUfnx9/PqrX1Gatp/L2GZnP83n7jMzn+RrCjG4NUOfPn5ckTZkyRY8++qgmTZqknTt3asyYMVq/fr3Ky8tlsVicjgkICJAkVVRUqKysTJLk7+9/xZqKigpJckmNujCbTQoNDa7z8d7IYgmql7WeyttnZD7P5+0zMp/nc+eMbg1Qfn5+kqRRo0YpOTlZktSpUyfl5ORo/fr1CgwMdNynVK061DRq1EiBgYGS9J1rgoIuP6muqFEXNptdJSUX63z89/Hz81FISKDL614LJSVlslptP7jGx8csiyWoVms9lbfPyHyez9tnZD7PV18zWixBtT6r5dYAFR4eLkmKiopy2t6hQwd9+OGHio+P18GDB532FRYWOo6tvuxWWFioyMhIpzXVtSMiIq66Rl1VVbn+L64nn5K1Wm21fk6MrPVU3j4j83k+b5+R+TyfO2d062/jm2++WcHBwfr888+dth88eFCtW7dWXFyccnJyHJf6JCkjI0PBwcGKjo5WWFiY2rVrp8zMTMf+qqoqZWdnKy4uTpJcUgMAAKAmtwaowMBApaamavny5fqf//kf/e///q9Wrlypjz/+WCNHjtTAgQPVrFkzTZgwQbm5udq9e7cWLlyoBx980HHP0oMPPqj169frzTff1KFDh/TMM8+ovLxcd911lyS5pAYAAEBNbr2EJ0ljxoxRUFCQFi1apIKCAkVGRmrp0qXq3bu3JGnNmjWaNWuW7r77bjVp0kT33nuvxowZ4zj+7rvvVmlpqRYvXqxz586pS5cuWr9+vZo2bSrp8s3gV1sDAACgJpPdbre7uwlvZLXadPbsBZfXDQjwlcUSpAkLP9Thb4tdXr8+RLZsosUTk1RUdOFHr1X7+poVGhpcq7WeyttnZD7P5+0zMp/nq68ZmzYNrvW9xp57RzIAAICbEKAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQS4JUKdOndJXX30lq9XqinIAAAANmuEAdf78eT399NPauHGjJOm9995T//79ddddd2nIkCHKy8szVK+goEAdO3a84mvbtm2SpAMHDiglJUU9evTQgAED9Nprrzkdb7PZtGTJEvXp00c9evTQQw89pBMnTjitcUUNAACAaoYD1IIFC7Rz5041adJEkpSWlqbo6GgtW7ZMvr6+SktLM1QvNzdXAQEB+sc//qG9e/c6vgYPHqyioiKNHDlSrVu3Vnp6usaOHau0tDSlp6c7jl+xYoU2bdqkOXPm6I033pDNZlNqaqoqKyslySU1AAAAavI1esCePXv01FNPaciQIfryyy/17bffavLkybrttttUVVWlGTNmGKp38OBBtW3bVs2bN79i36uvvio/Pz/Nnj1bvr6+ioyM1PHjx7V69WoNHTpUlZWVWrdunSZNmqSkpCRJ0qJFi9SnTx/t2rVLQ4YM0ZYtW666BgAAQE2Gz0CdO3dO7du3lyT9/e9/l6+vr2655RZJUpMmTVRRUWGo3tdff63IyMjv3Jedna34+Hj5+v4n5yUkJOjYsWM6ffq0cnNzdeHCBSUmJjr2WywWde7cWVlZWS6rAQAAUJPhM1AtW7bU119/rdjYWO3evVs9evRQSEiIpMuBqlWrVobqHTx4UKGhoRo+fLiOHj2qNm3a6JFHHlHfvn2Vn5+vqKgop/XVZ6ry8vKUn58vSWrRosUVa6r3uaJGXfn6uv5FjmazyeU1rxUfnx9/PqrX1Gatp/L2GZnP83n7jMzn+RrCjIYD1O9//3vNmzdPGzdu1JEjR7Rw4UJJ0qOPPqo9e/Zo2rRpta5VVVWlI0eOqEOHDnrqqacUEhKiHTt26OGHH9b69etVXl4uf39/p2MCAgIkSRUVFSorK5Ok71xTXFwsSS6pURdms0mhocF1Pt4bWSxB9bLWU3n7jMzn+bx9RubzfO6c0XCAeuCBBxQWFqasrCw9+uijGjx4sCTJz89PM2fO1LBhw2r/4L6+yszMlI+PjwIDAyVJXbp00TfffKO1a9cqMDDwihu5qy8RNmrUyHFMZWWl4/vqNUFBl59UV9SoC5vNrpKSi3U+/vv4+fkoJCTwxxc2QCUlZbJabT+4xsfHLIslqFZrPZW3z8h8ns/bZ2Q+z1dfM1osQbU+q2U4QEnSkCFDrri5etGiRXUppeDgK8/S3HTTTdq7d68iIiJUWFjotK/65/DwcFVVVTm2tW7d2mlNx44dJcklNeqqqsr1f3E9+ZSs1Wqr9XNiZK2n8vYZmc/zefuMzOf53DljrQLU9u3bDRX97W9/W6t133zzjYYNG6aVK1eqd+/eju1ffvmlOnTooE6dOumNN96Q1WqVj4+PJCkjI0Pt2rVTWFiYGjdurJCQEGVmZjrCT0lJiXJycpSSkiJJiouLu+oaAAAANdUqQD311FNOP5tMl29kttvtV2yTah+gIiMj1b59e82ePVuzZs1SaGiotmzZos8++0zp6ekKCwvTmjVrNHXqVKWmpuqLL77Qhg0bNGvWLEmX71tKSUlRWlqamjZtqpYtW2r+/PmKiIjQoEGDJElDhw696hoAAAA11SpA7dmzx/H9gQMH9OSTT2rMmDH61a9+pebNm6uoqEh/+9vftHTpUr3wwgu1fnCz2axVq1ZpwYIFmjBhgkpKStS5c2etX7/e8cq5NWvWaO7cuUpOTlazZs00efJkJScnO2qMGzdOVVVVmjZtmsrLyxUXF6e1a9fKz89Pkhwh7GpqAAAA1GSy1zyNVAt33nmnfvWrX+mhhx66Yt+rr76qrVu36n/+539c1qCnslptOnv2gsvrBgT4ymIJ0oSFH+rwt3V/leC1FNmyiRZPTFJR0YUfvVbt62tWaGhwrdZ6Km+fkfk8n7fPyHyer75mbNo0uNb3Ghu+I/nw4cPq3Lnzd+5r3769Tp48abQkAACARzEcoNq2bat33nnnO/dt3rz5ijetBAAA8DaG38Zg7NixGj9+vI4dO6b+/fsrNDRUp0+f1q5du3To0CG98sor9dEnAABAg2E4QA0aNEjLly/XihUrtHjxYtntdpnNZsXExGjDhg2KjY2tjz4BAAAaDMMBat++ffrZz36mAQMGqKKiQsXFxbruuuuu+CgUAAAAb2X4HqjHHntMu3btknT58+KaN29OeAIAAD8phgOUxWJx+sw4AACAnxrDl/BGjx6t5557TkePHlV0dLQaNWp0xZq4uDiXNAcAANAQGQ5QM2bMkPSfDw+u+REudrtdJpNJBw4ccFF7AAAADY/hAPXaa6/VRx8AAAAew3CAio+Pr48+AAAAPIbhACVJR48e1ZIlS7R//36VlJQoNDRUsbGxGjt2rCIjI13dIwAAQINiOEAdOnRIv//97+Xj46MBAwbo+uuv16lTp/TBBx/oww8/1NatWwlRAADAqxkOUGlpaWrVqpX+9Kc/qXHjxo7tpaWleuCBB7Ro0SItW7bMpU0CAAA0JIbfByorK0t/+MMfnMKTJDVu3FgPP/ywsrKyXNYcAABAQ2Q4QPn6+iogIOA79/n7+6uysvKqmwIAAGjIDAeorl27atOmTbLb7U7b7Xa7Nm7cqC5durisOQAAgIbI8D1Q48eP1z333KNf//rX+uUvf6lmzZrp1KlTev/993X06FGtX7++PvoEAABoMAwHqK5du2rNmjVasGCBli1b5nj38S5duuiVV17hY1wAAIDXMxygTp06pYSEBG3dulVlZWUqKSmRxWJRUFBQffQHAADQ4BgOUH379lXnzp01YMAA9e/fX507d66PvgAAABoswzeRL126VDfffLPS09N15513qm/fvpo+fbo++OADVVRU1EePAAAADYrhM1ADBw7UwIEDJV1+V/K9e/fqo48+0oQJE2QymZSQkKBVq1a5vFEAAICGok6fhVetTZs2OnfunC5cuKDS0lL9v//3//TRRx+5qjcAAIAGyXCAysjIUHZ2tvbv368vvvhC5eXlatu2rRISEvTggw+qd+/e9dEnAABAg2E4QI0YMUImk0k333yzZs2apcTERDVv3rw+egMAAGiQDAeoxx57TBkZGfrss880e/Zs9ezZU/Hx8erdu7e6dOkis9nwfekAAAAexXCAGjt2rMaOHavy8nJlZ2crIyNDO3fu1EsvvaSAgAD16tVLq1evro9eAQAAGoQ630QeGBioW2+9Ve3bt1ebNm20Z88effjhh9q7d68r+wMAAGhwDAeo4uJiZWRk6J///Kf27dunEydOKCQkRImJiXr++efVr1+/+ugTAACgwTAcoBISEiRJbdu21W233aZ+/fopNjZWvr5X9Y4IAAAAHsPwHd/PPPOMdu3apffee09TpkxRQkKCy8LT0aNHFRMTo23btjm2HThwQCkpKerRo4cGDBig1157zekYm82mJUuWqE+fPurRo4ceeughnThxwmmNK2oAAABUMxyg7rvvPt14440ub+TSpUuaNGmSLl686NhWVFSkkSNHqnXr1kpPT9fYsWOVlpam9PR0x5oVK1Zo06ZNmjNnjt544w3ZbDalpqaqsrLSZTUAAABqajDvObB06VKFhIQ4bduyZYv8/Pw0e/ZsRUZGaujQoRoxYoTjVX6VlZVat26dxo0bp6SkJEVHR2vRokXKz8/Xrl27XFYDAACgpgYRoLKysrR582bNmzfPaXt2drbi4+OdLhEmJCTo2LFjOn36tHJzc3XhwgUlJiY69lssFnXu3FlZWVkuqwEAAFBTrW5e+t///V+1atWqXt4ks6SkRJMnT9a0adPUokULp335+fmKiopy2lb9rud5eXnKz8+XpCuOa968uWOfK2rUla+v658vs9nk8prXio/Pjz8f1Wtqs9ZTefuMzOf5vH1G5vN8DWHGWgWo3/3ud1q+fLliY2P19NNPa8yYMS67D2rmzJmKiYnRHXfcccW+8vJy+fv7O20LCAiQJFVUVKisrEySvnNNcXGxy2rUhdlsUmhocJ2P90YWS1C9rPVU3j4j83k+b5+R+TyfO2esVYCqqKjQoUOHFBsbqzfffFP33HOPSwLU9u3blZ2drXfeeec79wcGBl5xI3dFRYUkqVGjRgoMDJR0+T6m6u+r1wQFBbmsRl3YbHaVlFz88YUG+fn5KCQk8McXNkAlJWWyWm0/uMbHxyyLJahWaz2Vt8/IfJ7P22dkPs9XXzNaLEG1PqtVqwCVkJCgmTNnatasWZKkYcOGfe9ak8mknJycWj14enq6zpw5o6SkJKftM2bM0LvvvquIiAgVFhY67av+OTw8XFVVVY5trVu3dlrTsWNHSXJJjbqqqnL9X1xPPiVrtdpq/ZwYWeupvH1G5vN83j4j83k+d85YqwCVlpamt956S0VFRVq2bJmGDh2qiIiIq37wtLQ0lZeXO20bNGiQxo0bp1//+td666239MYbb8hqtcrHx0eSlJGRoXbt2iksLEyNGzdWSEiIMjMzHeGnpKREOTk5SklJkSTFxcVddQ0AAICaahWgQkJCNHz4cElSZmamRo4cqcjIyKt+8PDw8O/cHhYWpvDwcA0dOlRr1qzR1KlTlZqaqi+++EIbNmxwnAnz9/dXSkqK0tLS1LRpU7Vs2VLz589XRESEBg0aJEkuqQEAAFCT4bcQ/9Of/iRJOnz4sPbv36/S0lKFhoaqZ8+eLglVNYWFhWnNmjWaO3eukpOT1axZM02ePFnJycmONePGjVNVVZWmTZum8vJyxcXFae3atfLz83NZDQAAgJpMdrvdbvSg6dOna+vWrap5qMlkUnJysp5//nmXNuiprFabzp694PK6AQG+sliCNGHhhzr8bd1fJXgtRbZsosUTk1RUdOFHr1X7+poVGhpcq7WeyttnZD7P5+0zMp/nq68ZmzYNdu1N5DW98sorSk9Pd9yn1KxZMxUWFuqtt97SypUrFRUVpREjRhgtCwAA4DEMB6i//OUvSk1N1SOPPOLY1qpVK40dO1aXLl3Sli1bCFAAAMCrGX5NfF5enhISEr5zX+/evXXy5MmrbgoAAKAhMxygWrZsqa+//vo79+Xm5qpp06ZX3RQAAEBDZjhADRkyREuXLtV7773nuIncbrfr3Xff1bJlyzR48GCXNwkAANCQGL4H6qGHHlJ2drYef/xxPfnkkwoNDVVRUZGsVqvi4+M1fvz4+ugTAACgwTAcoPz9/bV+/Xr9/e9/V1ZWloqLi9WkSRPFxcWpX79+9dEjAABAg2I4QFXr168fgQkAAPwkee4n0wIAALgJAQoAAMAgAhQAAIBBBCgAAACDahWgDh486Pi+U6dO+uKLLyRJVqtVnTp10ldffVU/3QEAADRAtXoVXnJyskJCQtSjRw/Z7XZ99dVXat++vYKCghxvpgkAAPBTUaszUPv379fChQt18803S5LmzZun+Ph43XHHHTKZTHrvvfeUmZmpkpKSem0WAACgIahVgAoODtYtt9yicePGSZJee+01vfPOO3rwwQdlt9u1Z88e/eEPf1B8fLz69+9frw0DAAC4W60u4W3dulW9evVS+/btJUkmk0mRkZFq27atpk2bprS0NHXu3FlHjx51ul8KAADAG9UqQP3pT3/SzJkzZbFYZDKZ9Oabb6qkpESdO3eWdDlQmUwmtW/f3hGyAAAAvFWtAtTbb7+t0tJS/etf/9Lo0aP1xRdf6N1331VxcbFMJpMWL16s2NhYRUdHKzo6Ws2bN6/vvgEAANym1p+F17hxY8dn382YMUPdunXT4cOHdfvttys4OFgff/yx1q5dq5KSEh04cKDeGgYAAHA3wx8mfMMNN8jf31+S1K5dO91www0aM2aMbrrpJklSQUGBazsEAABoYAwHqL/97W+O781ms9PPkhQeHn71XQEAADRgfJQLAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEFuD1BnzpzRk08+qYSEBMXExOjhhx/W4cOHHfsPHDiglJQU9ejRQwMGDNBrr73mdLzNZtOSJUvUp08f9ejRQw899JBOnDjhtMYVNQAAAKq5PUCNHTtWx48f1+rVq/WXv/xFgYGBGjFihMrKylRUVKSRI0eqdevWSk9P19ixY5WWlqb09HTH8StWrNCmTZs0Z84cvfHGG7LZbEpNTVVlZaUkuaQGAABATW4NUMXFxWrZsqWee+45devWTZGRkRozZowKCwv1zTffaMuWLfLz89Ps2bMVGRmpoUOHasSIEVq9erUkqbKyUuvWrdO4ceOUlJSk6OhoLVq0SPn5+dq1a5ckuaQGAABATW4NUE2aNNGCBQsUFRUlSTp79qw2bNigiIgIdejQQdnZ2YqPj5ev738+8zghIUHHjh3T6dOnlZubqwsXLigxMdGx32KxqHPnzsrKypIkl9QAAACoyffHl1wbzz77rLZs2SJ/f3+tXLlSjRo1Un5+viNcVWvevLkkKS8vT/n5+ZKkFi1aXLGmep8ratSVr6/r86nZbHJ5zWvFx+fHn4/qNbVZ66m8fUbm83zePiPzeb6GMGODCVAPPPCAhg0bpo0bN2rs2LHatGmTysvL5e/v77QuICBAklRRUaGysjJJ+s41xcXFkuSSGnVhNpsUGhpc5+O9kcUSVC9rPZW3z8h8ns/bZ2Q+z+fOGRtMgOrQoYMkae7cufr888/1+uuvKzAw8IobuSsqKiRJjRo1UmBgoKTL9zFVf1+9Jijo8pPqihp1YbPZVVJysc7Hfx8/Px+FhAT++MIGqKSkTFar7QfX+PiYZbEE1Wqtp/L2GZnP83n7jMzn+eprRoslqNZntdwaoM6ePat9+/bpF7/4heMeJbPZrA4dOqiwsFAREREqLCx0Oqb65/DwcFVVVTm2tW7d2mlNx44dJcklNeqqqsr1f3E9+ZSs1Wqr9XNiZK2n8vYZmc/zefuMzOf53DmjW38bnz59WhMnTtS+ffsc2y5duqScnBxFRkYqLi5On3zyiaxWq2N/RkaG2rVrp7CwMEVHRyskJESZmZmO/SUlJcrJyVFcXJwkuaQGAABATW4NUFFRUerbt6+ee+45ZWVl6eDBg3rqqadUUlKiESNGaOjQoTp//rymTp2qQ4cOadu2bdqwYYNGjx4t6fJ9SykpKUpLS9OePXuUm5urxx9/XBERERo0aJAkuaQGAABATW6/B2rhwoVasGCBHn/8cZWWlio2NlYbN27UDTfcIElas2aN5s6dq+TkZDVr1kyTJ09WcnKy4/hx48apqqpK06ZNU3l5ueLi4rR27Vr5+flJksLCwq66BgAAQE0mu91ud3cT3shqtens2QsurxsQ4CuLJUgTFn6ow9/W/VWC11JkyyZaPDFJRUUXfvRata+vWaGhwbVa66m8fUbm83zePiPzeb76mrFp0+Ba32vsuXckAwAAuAkBCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAgwhQAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABjk9gB17tw5TZ8+XX379lXPnj11zz33KDs727F/3759uvPOO9W9e3f98pe/1I4dO5yOr6io0KxZs5SYmKiYmBg98cQTOnv2rNMaV9QAAACo5vYANXHiRH366adauHCh0tPT1alTJ40aNUpHjhzR4cOHNXr0aPXp00fbtm3T7373O02ePFn79u1zHD9z5kzt3btXS5cu1auvvqojR45o3Lhxjv2uqAEAAFCTrzsf/Pjx4/r444+1adMm9erVS5L07LPP6h//+IfeeecdnTlzRh07dtTjjz8uSYqMjFROTo7WrFmjxMREFRQUaPv27Vq1apViY2MlSQsXLtQvf/lLffrpp4qJidGrr7561TUAAABqcusZqNDQUK1evVpdu3Z1bDOZTDKZTCopKVF2drYSExOdjklISNAnn3wiu92uTz75xLGtWrt27RQeHq6srCxJckkNAACAmtwaoCwWi/r16yd/f3/Htp07d+r48ePq06eP8vPzFRER4XRM8+bNVVZWpqKiIhUUFCg0NFQBAQFXrMnPz5ckl9QAAACoya2X8P7bv/71Lz399NMaNGiQkpKSVF5e7hSuJDl+rqysVFlZ2RX7JSkgIEAVFRWS5JIadeXr6/p8ajabXF7zWvHx+fHno3pNbdZ6Km+fkfk8n7fPyHyeryHM2GAC1O7duzVp0iT17NlTaWlpki6HmMrKSqd11T8HBQUpMDDwiv3S5VfVBQUFuaxGXZjNJoWGBtf5eG9ksdT++TSy1lN5+4zM5/m8fUbm83zunLFBBKjXX39dc+fO1S9/+Uv98Y9/dJwRatGihQoLC53WFhYWqlGjRmrcuLEiIiJ07tw5VVZWOp1FKiwsVHh4uMtq1IXNZldJycU6H/99/Px8FBIS6PK610JJSZmsVtsPrvHxMctiCarVWk/l7TMyn+fz9hmZz/PV14wWS1Ctz2q5PUBt2rRJc+bM0X333aepU6fKZPrPJarY2Fjt37/faX1GRoZ69uwps9msXr16yWaz6ZNPPnHcKH706FEVFBQoLi7OZTXqqqrK9X9xPfmUrNVqq/VzYmStp/L2GZnP83n7jMzn+dw5o1t/Gx89elTPP/+8fv7zn2v06NE6ffq0Tp06pVOnTqm0tFT33XefvvjiC6Wlpenw4cNat26d3n//faWmpkqSwsPDdfvtt2vatGnKzMzUF198oYkTJyo+Pl49evSQJJfUAAAAqMmtZ6B27typS5cu6a9//av++te/Ou1LTk7WvHnztGLFCs2fP1+vvvqqWrVqpfnz5zu9LcGcOXP0/PPP69FHH5Uk9e3bV9OmTXPsv+mmm666BgAAQE0mu91ud3cT3shqtens2QsurxsQ4CuLJUgTFn6ow98Wu7x+fYhs2USLJyapqOjCj55q9fU1KzQ0uFZrPZW3z8h8ns/bZ2Q+z1dfMzZtGlzrW2U894YaAAAANyFAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwyNfdDeCnw8fnx/N69ZrarK1vNptdNpvd3W0AABogAhTq3XWNA2Sz2WWxBNX6GCNr64vVatO5cxcJUQCAKxCgUO9CgvxkNpuUtvETnSwodXc7tdIqvLEmDe8ls9lEgAIAXIEAhWvmZEGpDn9b7O42AAC4au6/0QQAAMDDEKAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAACAQQQoAAAAgwhQAAAABjWoAPXyyy/rvvvuc9p24MABpaSkqEePHhowYIBee+01p/02m01LlixRnz591KNHDz300EM6ceKEy2sAAABUazABauPGjVq8eLHTtqKiIo0cOVKtW7dWenq6xo4dq7S0NKWnpzvWrFixQps2bdKcOXP0xhtvyGazKTU1VZWVlS6rAQAAUJPbPwuvoKBAM2bMUGZmptq2beu0b8uWLfLz89Ps2bPl6+uryMhIHT9+XKtXr9bQoUNVWVmpdevWadKkSUpKSpIkLVq0SH369NGuXbs0ZMgQl9QAAACoye1noL766iv5+fnp7bffVvfu3Z32ZWdnKz4+Xr6+/8l5CQkJOnbsmE6fPq3c3FxduHBBiYmJjv0Wi0WdO3dWVlaWy2oAAADU5PYzUAMGDNCAAQO+c19+fr6ioqKctjVv3lySlJeXp/z8fElSixYtrlhTvc8VNerK19f1+dRsNrm8Jr6fj4/r/wyra9ZH7YaA+Tyft8/IfJ6vIczo9gD1Q8rLy+Xv7++0LSAgQJJUUVGhsrIySfrONcXFxS6rURdms0mhocF1Ph4Ng8US5JG1GwLm83zePiPzeT53ztigA1RgYOAVN3JXVFRIkho1aqTAwEBJUmVlpeP76jVBQUEuq1EXNptdJSUX63z89/Hz81FISOCPL4RLlJSUyWq1ubSmj49ZFktQvdRuCJjP83n7jMzn+eprRoslqNZntRp0gIqIiFBhYaHTtuqfw8PDVVVV5djWunVrpzUdO3Z0WY26qqpy/V9cbz4l2xBZrbZ6+XOs79oNAfN5Pm+fkfk8nztnbNC/jePi4vTJJ5/IarU6tmVkZKhdu3YKCwtTdHS0QkJClJmZ6dhfUlKinJwcxcXFuawGAABATQ06QA0dOlTnz5/X1KlTdejQIW3btk0bNmzQ6NGjJV2+byklJUVpaWnas2ePcnNz9fjjjysiIkKDBg1yWQ0AAICaGvQlvLCwMK1Zs0Zz585VcnKymjVrpsmTJys5OdmxZty4caqqqtK0adNUXl6uuLg4rV27Vn5+fi6rAQAAUJPJbrfb3d2EN7JabTp79oLL6wYE+MpiCdKEhR/q8Ld1f5XgtdQvpqUmpcR6VM+RLZto8cQkFRVdcPn1dV9fs0JDg+uldkPAfJ7P22dkPs9XXzM2bRpc63uNG/QlPAAAgIaIAAUAAGAQAQoAAMAgAhQAAIBBBCgAAACDCFAAAAAGEaAAAAAMatBvpAm4W3189mB1zfqobbPZZbPx1m4AUN8IUMB3uK5xgGw2uyyWoHp7jPqobbXadO7cRUIUANQzAhTwHUKC/GQ2m5S28ROdLCh1dzu10iq8sSYN7yWz2USAAoB6RoACfsDJglKP+fgZAMC1w03kAAAABhGgAAAADCJAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEG8DxTgZerjI2Lq8vi17YOPnwHgiQhQgJe4Fh8/Y0Rt++DjZwB4IgIU4CX4+BkAuHYIUICX4eNnAKD+cRM5AACAQZyBAoA6cPfN+kZxsz7gWgQoADDAZDI1qJv1a4ub9QHXIkABgAFms4mb9QEQoACgLjzxZv3aXnY0+l5e9YlLj2ioCFAA4OXq+h5hDeEyJZce0VARoADAy3nie4RJ/7n06OfnI6vV5rK69X2GjbNmPw0EKAD4ifC0y471/e769VXXarWptLRcdrt7QlRdAiKhzzgCFACgQfLEM2ed2jXVQ7/pquuua+TuVgwFRC6VGkeA+j82m03Lli3T1q1bVVpaqri4OE2fPl033niju1sDgJ80Tzpz1qp5iMeFvvq6VFqfGsILHAhQ/2fFihXatGmT5s2bp4iICM2fP1+pqal655135O/v7+72AAAexJNCX0P7IPLastnsMplMbnt8ApSkyspKrVu3TpMmTVJSUpIkadGiRerTp4927dqlIUOGuLdBAADqiSdeKq353mbuQoCSlJubqwsXLigxMdGxzWKxqHPnzsrKyiJAAQC8niedNWsITHZ3vUygAdm1a5cee+wxff755woMDHRsHz9+vMrLy/Xyyy8brmm3188rGkwmyWw261xphao85Fp1gL+PGjfyp+d65ok9+/qY/+/ygWf0e9nldyL3pOfZE/9uSJ7ZNz1fGzX/7XBlijGbTbW+LMgZKEllZWWSdMW9TgEBASourlsaN5lM8vGpv1OL1zUOqLfa9YWerw1P7Nlsdv8NoUZ54vPsiT1Lntk3PV8b7vy3w/P+1aoH1WedKisrnbZXVFQoKMizbqoDAAD1jwAlqUWLFpKkwsJCp+2FhYUKDw93R0sAAKABI0BJio6OVkhIiDIzMx3bSkpKlJOTo7i4ODd2BgAAGiLugdLle59SUlKUlpampk2bqmXLlpo/f74iIiI0aNAgd7cHAAAaGALU/xk3bpyqqqo0bdo0lZeXKy4uTmvXrpWfn5+7WwMAAA0Mb2MAAABgEPdAAQAAGESAAgAAMIgABQAAYBABCgAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoDzQyy+/rPvuu8/dbbjcuXPnNH36dPXt21c9e/bUPffco+zsbHe35TJnzpzRk08+qYSEBMXExOjhhx/W4cOH3d1WvTh69KhiYmK0bds2d7fiUgUFBerYseMVX9405/bt2zV48GB17dpVt99+u9577z13t+QymZmZ3/nn17FjR912223ubs8lqqqq9NJLL6l///6KiYnR8OHD9dlnn7m7LZc5f/68ZsyYoVtvvVXx8fGaNGmSzpw545ZeCFAeZuPGjVq8eLG726gXEydO1KeffqqFCxcqPT1dnTp10qhRo3TkyBF3t+YSY8eO1fHjx7V69Wr95S9/UWBgoEaMGKGysjJ3t+ZSly5d0qRJk3Tx4kV3t+Jyubm5CggI0D/+8Q/t3bvX8TV48GB3t+YSb731lqZOnarhw4drx44dGjJkiOO/S28QExPj9Oe2d+9eLVu2TCaTSWPGjHF3ey6xcuVKbd26VXPmzNH27dvVrl07paamqrCw0N2tucT48eP197//XXPnztXGjRtVVlam+++/X5WVlde8FwKUhygoKNAf/vAHpaWlqW3btu5ux+WOHz+ujz/+WDNnzlRsbKzatWunZ599Vs2bN9c777zj7vauWnFxsVq2bKnnnntO3bp1U2RkpMaMGaPCwkJ988037m7PpZYuXaqQkBB3t1EvDh48qLZt26p58+Zq1qyZ4yswMNDdrV01u92ul156Sffff7+GDx+u1q1b65FHHtHPfvYz7d+/393tuYS/v7/Tn1twcLBeeOEFJScna+jQoe5uzyV2796tIUOG6NZbb1WbNm301FNPqbS01CvOQh04cEB79+7V7Nmz1a9fP91000168cUXVVhYqB07dlzzfghQHuKrr76Sn5+f3n77bXXv3t3d7bhcaGioVq9era5duzq2mUwmmUwmlZSUuLEz12jSpIkWLFigqKgoSdLZs2e1YcMGRUREqEOHDm7uznWysrK0efNmzZs3z92t1Iuvv/5akZGR7m6jXhw9elTffvut7rjjDqfta9eu1ejRo93UVf1atWqVysrKNGXKFHe34jJhYWH64IMPdPLkSVmtVm3evFn+/v6Kjo52d2tX7dixY5Kk2NhYx7bg4GC1adPGLSGfDxP2EAMGDNCAAQPc3Ua9sVgs6tevn9O2nTt36vjx43rmmWfc1FX9ePbZZ7Vlyxb5+/tr5cqVatSokbtbcomSkhJNnjxZ06ZNU4sWLdzdTr04ePCgQkNDNXz4cB09elRt2rTRI488or59+7q7tat29OhRSdLFixc1atQo5eTkqFWrVnrkkUe88t+e6v+JeeKJJ3Tddde5ux2XmTp1qsaPH6/bbrtNPj4+MpvNWrp0qVq3bu3u1q5a8+bNJUl5eXmO/5GxWq3Kz89XWFjYNe+HM1BokP71r3/p6aef1qBBg5SUlOTudlzqgQceUHp6uoYMGaKxY8fqq6++cndLLjFz5kzFxMRccQbDW1RVVenIkSMqLi7WY489ptWrV6tHjx56+OGHtW/fPne3d9XOnz8vSZoyZYqGDBmidevW6ZZbbtGYMWO8Yr7/tmnTJjVu3FjDhg1zdysudejQITVu3FjLly/X5s2bdeedd2rSpEk6cOCAu1u7al27dlX79u01Y8YMFRQUqLy8XAsWLFBRUZEuXbp0zfvhDBQanN27d2vSpEnq2bOn0tLS3N2Oy1Vfsps7d64+//xzvf7663rhhRfc3NXV2b59u7Kzs73ifrXv4+vrq8zMTPn4+DjueerSpYu++eYbrV27VomJiW7u8Or4+flJkkaNGqXk5GRJUqdOnZSTk6P169d7/Hz/bfv27frtb3/rFfevVcvLy9MTTzyhDRs2OC5zde3aVYcOHdLSpUu1YsUKN3d4dfz9/bVs2TJNnjxZffv2lZ+fn+644w71799fZvO1Px/EGSg0KK+//roee+wx9e/fX6tWrVJAQIC7W3KJs2fPaseOHaqqqnJsM5vN6tChg1e8OiY9PV1nzpxRUlKSYmJiFBMTI0maMWOGUlNT3dyd6wQHB1/xC/emm25SQUGBmzpynfDwcEly3KdXrUOHDjp58qQ7Wqo3ubm5OnHihNedLf3888916dIlp3tJJal79+46fvy4m7pyrcjISKWnpyszM1MZGRl64YUXlJ+f75ZLlAQoNBibNm3SnDlzNHz4cC1cuFD+/v7ubsllTp8+rYkTJzpdCrl06ZJycnK84qbktLQ0vfvuu9q+fbvjS5LGjRunuXPnurc5F/nmm2/Us2dPZWZmOm3/8ssvveKFADfffLOCg4P1+eefO20/ePCgV9w/U1N2drbCwsK84sbqmiIiIiRdfrFDTdWvHvV058+fV0pKinJzc3XdddcpJCREJ0+eVE5Ojm655ZZr3g+X8NAgHD16VM8//7x+/vOfa/To0Tp9+rRjX2BgoBo3buzG7q5eVFSU+vbtq+eee07PPfecmjRpopdfflklJSUaMWKEu9u7atVnL/5bWFjY9+7zNJGRkWrfvr1mz56tWbNmKTQ0VFu2bNFnn32m9PR0d7d31QIDA5Wamqrly5crPDxc3bp1044dO/Txxx9rw4YN7m7PpXJyctSxY0d3t+Fy3bp1U69evTRlyhTNmDFDERER2r59u/bt26c///nP7m7vqoWEhMhut2vu3LmaPn26ysvL9cwzzyghIcEtl5gJUGgQdu7cqUuXLumvf/2r/vrXvzrtS05O9oqXxS9cuFALFizQ448/rtLSUsXGxmrjxo264YYb3N0aasFsNmvVqlVasGCBJkyYoJKSEnXu3Fnr16+/4rKXpxozZoyCgoK0aNEiFRQUKDIyUkuXLlXv3r3d3ZpLnTp1yqteeVfNbDZr5cqVWrx4sZ5++mkVFxcrKipKGzZs8Jq3v1m4cKHmzJmje+65R/7+/ho0aJCefPJJt/Ristvtdrc8MgAAgIfiHigAAACDCFAAAAAGEaAAAAAMIkABAAAYRIACAAAwiAAFAABgEAEKAADAIAIUAK+zdOnSH32n6a+//lq//e1v1aVLFw0ePPgadQbAW/BO5AB+kpYvX65///vfWr58uZo2berudgB4GAIUgJ+koqIiRUVFqV+/fu5uBYAH4hIeAJdKTk7WI4884rRt4MCBSkpKcto2ZswYjRo1SpJktVq1ceNG3XHHHerWrZuSkpKUlpamiooKx/qnnnpKDzzwgGbMmKGePXtq8ODBslqtqqio0AsvvKBbbrlFMTExevrpp52O+y4dO3bU/v37lZWVpY4dO2rbtm3atm2bOnfurK1bt+qWW25RfHy8Dh06JEnavXu37rzzTnXt2lW33HKLnnvuOV28eNGpZkZGhu6++251795dv/rVr7Rnzx79/Oc/19KlSyVJmZmZ6tixozIzM52Ou++++3Tfffc5bdu6datuv/12denSRUlJSVq6dKmsVqvTczFixAilp6frF7/4hbp06aLf/OY3+uijj5zqHDlyRI8++qji4+MVFxen0aNH6/Dhw5KkoUOH6ve///0Vz82IESM0cuTIH3z+ABCgALhYv379tH//fscv/JMnT+rEiRPKy8vTiRMnJEmXLl3Svn37HKFq+vTpeuGFFzRw4ECtXLlSw4cP1+uvv64xY8ao5sd1ZmdnKy8vT8uXL9cTTzwhHx8fPfnkk9qyZYtGjx6txYsXq7i4WBs2bPjBHjdv3qzOnTurc+fO2rx5s6MPq9WqdevWae7cuXr66acVGRmpd955R2PHjlX79u21fPlyPfroo3r77bedevvqq6+UmpqqkJAQLVmyRPfee6+eeeYZnT592vDz9/LLL+vZZ59VYmKiVq1apeHDh+uVV17Rs88+67Tuyy+/1Nq1azVu3DgtX75cPj4+euyxx1RcXCxJKigo0LBhw3Ts2DHNnDlT8+fP1+nTp/XAAw/o3Llzuuuuu/Tpp5/q+PHjjpp5eXnKzMzUnXfeabhv4CfHDgAu9Omnn9qjoqLs//rXv+x2u92+ZcsW+6BBg+w9e/a0p6en2+12u33fvn32qKgo+4kTJ+zffPONPSoqyv7yyy871dm+fbs9KirK/uGHH9rtdrt9ypQp9qioKHteXp5jzcGDB+1RUVH2TZs2ObZZrVb74MGD7VFRUT/YZ0pKij0lJcXxc3p6uj0qKsq+fft2xzabzWbv27evfdSoUU7H/vOf/7RHRUXZP/jgA7vdbrc/9thj9j59+tgrKioca9566y17VFSUfcmSJXa73W7PyMiwR0VF2TMyMr63j5KSEnu3bt3s06dPd1qzZcsWe1RUlP3gwYNOz8Xx48cda/bv32+Pioqyv//++3a73W6fN2+evVu3bvbCwkLHmry8PHtSUpL9ww8/dDzWSy+95Ni/cuVKe69evexlZWU/+NwBsNs5AwXApbp166bQ0FD985//lHT50lbv3r3VvXt3ZWVlSZI++ugj3XTTTWrVqpX2798vSbr99tud6tx+++3y8fFxuuR13XXXKSIiwvFzdna2JGnAgAGObWazWb/4xS/q3H+nTp0c3x85ckT5+fkaMGCAqqqqHF9xcXEKCQnRxx9/7OijT58+8vf3dxw7ePBg+foau830008/VXl5+RWPVz1f9eNJUtOmTdW6dWvHz9XPS1lZmSTpk08+UY8ePdSsWTOnNR988IH69eunxo0ba9CgQXr77bcd+998800NHjxYgYGBhvoGfoq4iRyAS5nNZvXt21f79u3T2LFjlZGRoWeeeUY33HCDtm7dKkn6xz/+of79+0uS45JTzV/0kuTr66vQ0FCVlpY6tgUHBzutqT42NDTUaft/1zKiUaNGju/PnTsnSZo1a5ZmzZp1xdrCwkJHH//9Sj5fX1+FhYUZeuzqx3v44Ye/c3/140lSUFCQ0z6TySRJstlsjlqtWrX6wce766679Pbbbys7O1s+Pj46duyY/vjHPxrqGfipIkABcLmkpCRNnjxZX3zxhU6fPq34+HjdcMMNWrRokT799FMdPHhQM2fOlCQ1adJEknTq1Cm1bNnSUePSpUsqKiq6IhzVVL3v9OnTuuGGGxzbq4PI1bJYLJKkyZMnKz4+/or91b2HhoZ+5/1O1QFPujLgVLtw4YIjGFY/Xlpamtq2bXtFveuvv77WvTdu3Fhnz569Yvu+ffvUqlUr3XjjjYqPj1fr1q31/vvvy2w2q3379urRo0etHwP4KeMSHgCXu/XWW2W32/Xyyy+rXbt2atasmbp27apGjRpp/vz5Cg0NVUxMjCQ5gsmOHTucauzYsUNWq1W9evX63sdJSEiQJL3//vtO2z/44AOXzNG+fXuFhYXp5MmT6tq1q+MrPDxcCxYsUE5OjiQpMTFRH330kePymST985//VHl5uePnkJAQSVJ+fr5jW3FxseNVcZLUvXt3+fn5qaCgwOnxfH19tXDhQp08ebLWvcfGxurzzz93ClFnzpxRamqq/v73v0u6HOruvPNO7d69W3/729+UnJxs8BkCfro4AwXA5SwWi2JiYrR7924NGzZM0uVLWrGxsfroo4/0m9/8Rmbz5f9/69Chg5KTk7VkyRKVlZUpLi5OBw4c0LJly9S7d2/16dPnex+nTZs2GjZsmBYtWqSqqip16tRJb731lr7++muXzOHj46PHH39c06dPl4+Pj/r376+SkhKtWLFCBQUFuvnmmyVJY8eO1d/+9jeNGjVKqampOnfunBYuXOhUq2PHjmrRooWWL1+ukJAQmUwmvfzyy06X4kJDQ5WamqqXXnpJ58+fV+/evVVQUKCXXnpJJpNJ0dHRte59xIgR2r59u1JTUzV69Gj5+flp5cqVioiI0B133OFYd+eddzreauE3v/nN1TxdwE8KAQpAvejXr5+ysrLUu3dvx7bevXvro48+uuI9oebOnas2bdooPT1dr7zyipo3b677779fY8aMcQSt7zNjxgxdf/31ev3111VcXKw+ffroD3/4gxYvXuySOX73u98pODhYa9as0ebNm9WoUSP17NlTaWlpuvHGGyVJbdu21caNG/XCCy9owoQJatasmaZMmaJJkyY56vj4+GjJkiV6/vnnNXHiRF1//fV64IEHdOTIER09etSxrvr4TZs2ac2aNWrSpIkSExM1ceJENW7cuNZ9t2jRQps2bdL8+fP11FNPyd/fX71799aiRYsclx4lKTw8XNHR0br++usVHh7ugmcM+Gkw2e013mQFAOAyHTt21KOPPqrHHnvM3a18r4KCAvXv319LlizRwIED3d0O4DE4AwUAP0EHDhzQnj17tHPnTrVt29bprSAA/DhuIgeAn6CKigqtX79eVqtVCxcu/NFLpQCccQkPAADAIP6XAwAAwCACFAAAgEEEKAAAAIMIUAAAAAYRoAAAAAwiQAEAABhEgAIAADCIAAUAAGAQAQoAAMCg/w/6fHpkx/8HCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist([v for v in personality['all'].values() if v < 10],bins=10)\n",
    "plt.ylabel(\"# of words\")\n",
    "plt.xlabel(\"word frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QspSnpFzVAAp"
   },
   "source": [
    "There are a lot of words that only appear once! We'll print out that value here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBsFSL29VAAw",
    "outputId": "64e625a1-15be-4541-b802-632e803b903a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81268"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([v for v in personality['all'].values() if v == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of words do you think would appear once? Let's print out a few of these rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7w88w74w5', 'milliionaire', 'daaaaaays', 'howtosay', 'isntaernt', 'infj8s', 'abreviations', 'accosted', 'cialis', 'teastained', '91603', 'ahahahai', 'ryuuji', 'yoloing', 'unstructuredramblinglongrandom', 'jeeves', 'sellcommercial', 'ninetales', 'shindlers', 'skillfocused', '29608', 'age23', 'hays', 'whatcouldpossiblybecalledheroicbymostpeople', '4458644588445894459044592', 'spsjs', '590290', 'hyperempathy', 'navelunderactive12', 'commitmentregardless', 'webz', '710794', 'ultranumb', 'songamong', 'spidy', '249186', 'phenomenology', 'nonaccusatory', 'neonzebradegree', 'mannnnn', 'neighbouryou', 'themesleves', 'up◠‿◠✿', 'momstressed', 'aptness', 'messege', 'kareem', 'wenders', 'togglemute', 'fbemail', 'alterable', 'doeither', 'nexflix', 'clingyneedyoverly', 'perfectnope', 'slided', 'politefriendly', 'libertines', 'mingyur', 'thread…', 'favouritesbut', 'éxodo', 'oh3', 'selfadmiration', '525100', 'a440', 'slink', '03534', 'followedstory', 'didntknow', '12yo', 'hrmone', 'nondessert', 'weirdinspiringreal', 'chocolatechipcookies35897', 'humornot', 'observationsgeneral', 'cantabelle', 'newlyjoined', 'wooooooo', 'mmhhhh', 'stiffer', '41infj', 'waiteretc', 'proprietor', 'postsdiscussion', 'conclusionshow', 'footnote', 'hospicesthey', 'indifferenceelie', 'anthropomorphism', '157194', '34logical', 'hofgarten', 'clooneys', 'girlscouts', 'emotinal', '2rational4poetry', 'camelot', 'sweetiehoney']\n"
     ]
    }
   ],
   "source": [
    "rare_words = [k for k, v in personality['all'].items() if v==1] \n",
    "print(rare_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of these words don't make sense, but before we decide to remove them, let's see how much data we'll be left with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amu9ABO8VAAz",
    "outputId": "3d99bd9f-f5eb-4c26-f3e4-d1751eee8920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18193\n",
      "7998579\n"
     ]
    }
   ],
   "source": [
    "# how many words appear more than 10 times?\n",
    "# how many words of the total does that account for?\n",
    "print(len([v for v in personality['all'].values() if v >= 10]))\n",
    "occurs_more_than_10_times = sum([v for v in personality['all'].values() if v >= 10])\n",
    "print(occurs_more_than_10_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwmyzJewVAA2",
    "outputId": "7e64933d-1034-4c8f-d160-36472eeb154f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9750243372740254"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurs_more_than_10_times/total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxW-TeheVAA4"
   },
   "source": [
    "Using words that appear more than 10 times seems much more useful!  And this accounts for 97% of all the words!\n",
    "\n",
    "Finally, let's remove all words that occur less than 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZNdn2n6VAA4",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "max_count = 10\n",
    "remaining_word_index = [k for k, v in personality['all'].items() if v > max_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing\n",
    "Remember our Hypothesis from earlier?:\n",
    "\n",
    "- Introverts tend to use the word `I` more than extroverts\n",
    "- Conversely, Extroverts tend to favour the word `you`\n",
    "\n",
    "Let's see if we finally have what we need to test it out. We'll first create one big dataframe with the word counts by personality profile (this may take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW5qiwvrVAA5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hm = []\n",
    "for p, p_bow in personality.items():\n",
    "    df_bow = pd.DataFrame([(k, v) for k, v in p_bow.items() if k in remaining_word_index], columns=['Word', p])\n",
    "    df_bow.set_index('Word', inplace=True)\n",
    "    hm.append(df_bow)\n",
    "\n",
    "# create one big dataframe\n",
    "df_bow = pd.concat(hm, axis=1)\n",
    "df_bow.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top 10 words which appear most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaKScx05VAA7",
    "outputId": "5bcaa326-858b-478f-9f88-f582ce599a20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>INTP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>67821.0</td>\n",
       "      <td>27381.0</td>\n",
       "      <td>52046.0</td>\n",
       "      <td>43810.0</td>\n",
       "      <td>8875.0</td>\n",
       "      <td>8683.0</td>\n",
       "      <td>87642.0</td>\n",
       "      <td>31156.0</td>\n",
       "      <td>11148.0</td>\n",
       "      <td>13883.0</td>\n",
       "      <td>8037.0</td>\n",
       "      <td>8169.0</td>\n",
       "      <td>3704.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>378073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>39658.0</td>\n",
       "      <td>18993.0</td>\n",
       "      <td>35864.0</td>\n",
       "      <td>30497.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>48004.0</td>\n",
       "      <td>16454.0</td>\n",
       "      <td>6131.0</td>\n",
       "      <td>8893.0</td>\n",
       "      <td>4111.0</td>\n",
       "      <td>5141.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>230224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>40231.0</td>\n",
       "      <td>17852.0</td>\n",
       "      <td>33005.0</td>\n",
       "      <td>28753.0</td>\n",
       "      <td>5889.0</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>48996.0</td>\n",
       "      <td>16945.0</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>5106.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>227371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>31931.0</td>\n",
       "      <td>14728.0</td>\n",
       "      <td>26692.0</td>\n",
       "      <td>22778.0</td>\n",
       "      <td>4748.0</td>\n",
       "      <td>3966.0</td>\n",
       "      <td>40375.0</td>\n",
       "      <td>13846.0</td>\n",
       "      <td>4825.0</td>\n",
       "      <td>7124.0</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>4033.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>182870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>31628.0</td>\n",
       "      <td>14236.0</td>\n",
       "      <td>24880.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>40709.0</td>\n",
       "      <td>15002.0</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>6540.0</td>\n",
       "      <td>3571.0</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>180691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>24312.0</td>\n",
       "      <td>11335.0</td>\n",
       "      <td>21372.0</td>\n",
       "      <td>17857.0</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>3114.0</td>\n",
       "      <td>29576.0</td>\n",
       "      <td>10217.0</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>4962.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>2976.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>138561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>22207.0</td>\n",
       "      <td>10870.0</td>\n",
       "      <td>17186.0</td>\n",
       "      <td>15997.0</td>\n",
       "      <td>3815.0</td>\n",
       "      <td>3048.0</td>\n",
       "      <td>24954.0</td>\n",
       "      <td>10315.0</td>\n",
       "      <td>3331.0</td>\n",
       "      <td>4696.0</td>\n",
       "      <td>2185.0</td>\n",
       "      <td>2731.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>124672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>19444.0</td>\n",
       "      <td>8947.0</td>\n",
       "      <td>16384.0</td>\n",
       "      <td>14432.0</td>\n",
       "      <td>2906.0</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>23437.0</td>\n",
       "      <td>8583.0</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>4054.0</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>2207.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>110718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>18357.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>15685.0</td>\n",
       "      <td>13167.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>2278.0</td>\n",
       "      <td>22511.0</td>\n",
       "      <td>8010.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>4244.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>2285.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>104808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>18237.0</td>\n",
       "      <td>8903.0</td>\n",
       "      <td>15888.0</td>\n",
       "      <td>14293.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>21068.0</td>\n",
       "      <td>7769.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>3704.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>2186.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>104779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         INFJ     ENTP     INTP     INTJ    ENTJ    ENFJ     INFP     ENFP  \\\n",
       "Word                                                                         \n",
       "i     67821.0  27381.0  52046.0  43810.0  8875.0  8683.0  87642.0  31156.0   \n",
       "the   39658.0  18993.0  35864.0  30497.0  6132.0  5018.0  48004.0  16454.0   \n",
       "to    40231.0  17852.0  33005.0  28753.0  5889.0  5471.0  48996.0  16945.0   \n",
       "a     31931.0  14728.0  26692.0  22778.0  4748.0  3966.0  40375.0  13846.0   \n",
       "and   31628.0  14236.0  24880.0  21568.0  4564.0  4343.0  40709.0  15002.0   \n",
       "of    24312.0  11335.0  21372.0  17857.0  3499.0  3114.0  29576.0  10217.0   \n",
       "you   22207.0  10870.0  17186.0  15997.0  3815.0  3048.0  24954.0  10315.0   \n",
       "that  19444.0   8947.0  16384.0  14432.0  2906.0  2611.0  23437.0   8583.0   \n",
       "it    18357.0   8257.0  15685.0  13167.0  2601.0  2278.0  22511.0   8010.0   \n",
       "is    18237.0   8903.0  15888.0  14293.0  3000.0  2404.0  21068.0   7769.0   \n",
       "\n",
       "         ISFP     ISTP    ISFJ    ISTJ    ESTP    ESFP    ESTJ    ESFJ     all  \n",
       "Word                                                                            \n",
       "i     11148.0  13883.0  8037.0  8169.0  3704.0  1696.0  1856.0  2166.0  378073  \n",
       "the    6131.0   8893.0  4111.0  5141.0  2191.0   937.0  1000.0  1200.0  230224  \n",
       "to     6264.0   8725.0  4607.0  5106.0  2254.0   972.0  1078.0  1223.0  227371  \n",
       "a      4825.0   7124.0  3333.0  4033.0  1868.0   796.0   841.0   986.0  182870  \n",
       "and    5153.0   6540.0  3571.0  3827.0  1905.0   834.0   943.0   988.0  180691  \n",
       "of     3580.0   4962.0  2475.0  2976.0  1300.0   557.0   650.0   779.0  138561  \n",
       "you    3331.0   4696.0  2185.0  2731.0  1396.0   651.0   651.0   639.0  124672  \n",
       "that   2931.0   4054.0  2033.0  2207.0  1063.0   550.0   521.0   615.0  110718  \n",
       "it     2909.0   4244.0  2046.0  2285.0  1065.0   434.0   469.0   490.0  104808  \n",
       "is     2726.0   3704.0  1879.0  2186.0  1121.0   482.0   554.0   565.0  104779  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MTEdKrZVAA8"
   },
   "source": [
    "This isn't very helpful at all, is it? It's very difficult to extract insights from this data.  Let's see if we can use the $chi^2$ test to see whether Introverts favour the word **`I`**. \n",
    "\n",
    "The $chi^2$ test looks at observed versus expected results and lets us know where the greatest differences from expected values are.  The bigger the statistic, the greater the difference from expectation.  The formula is \n",
    "\n",
    "$$𝑐ℎ𝑖^2 = \\sum{\\frac{(𝑂𝑏𝑠𝑒𝑟𝑣𝑒𝑑 −𝑒𝑥𝑝𝑒𝑐𝑡𝑒𝑑)^2}{𝑒𝑥𝑝𝑒𝑐𝑡𝑒𝑑}}$$\n",
    "\n",
    "The $chi^2$ test will compare the **observed frequencies** of word usage by **introverts** to the **expected frequencies** based on the overall population and indicate the extent of this difference for each word.\n",
    "\n",
    "Using the $chi^2$ statistic over simply comparing the observed percentages, i.e `I_perc`, means that we are considering both the observed (or word usage by introverts) and expected frequencies(or the overall populations word usage) for each word, taking into account the sample size. This helps us determine whether the differences between observed and expected frequencies are statistically significant, accounting for variability due to sample size.\n",
    "\n",
    "We'll do this first by extracting introvert types only from all the personality types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eTstsUzVAA8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "intro_types_i = [p for p in type_labels if p[0] == 'I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create an introvert total word count column, which sums the counts of all introvert columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7F3a0V80VAA_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_bow['I'] = df_bow[intro_types_i].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll calculate and add percentage columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tESewJzZVABA",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for col in ['I', 'all']:\n",
    "    df_bow[col+'_perc'] = df_bow[col] / df_bow[col].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print off the dataframe to view what we've done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>INTP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>all</th>\n",
       "      <th>I</th>\n",
       "      <th>I_perc</th>\n",
       "      <th>all_perc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>67821.0</td>\n",
       "      <td>27381.0</td>\n",
       "      <td>52046.0</td>\n",
       "      <td>43810.0</td>\n",
       "      <td>8875.0</td>\n",
       "      <td>8683.0</td>\n",
       "      <td>87642.0</td>\n",
       "      <td>31156.0</td>\n",
       "      <td>11148.0</td>\n",
       "      <td>13883.0</td>\n",
       "      <td>8037.0</td>\n",
       "      <td>8169.0</td>\n",
       "      <td>3704.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>378073</td>\n",
       "      <td>292556.0</td>\n",
       "      <td>0.047701</td>\n",
       "      <td>0.047328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>39658.0</td>\n",
       "      <td>18993.0</td>\n",
       "      <td>35864.0</td>\n",
       "      <td>30497.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>48004.0</td>\n",
       "      <td>16454.0</td>\n",
       "      <td>6131.0</td>\n",
       "      <td>8893.0</td>\n",
       "      <td>4111.0</td>\n",
       "      <td>5141.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>230224</td>\n",
       "      <td>178299.0</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>0.028820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>40231.0</td>\n",
       "      <td>17852.0</td>\n",
       "      <td>33005.0</td>\n",
       "      <td>28753.0</td>\n",
       "      <td>5889.0</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>48996.0</td>\n",
       "      <td>16945.0</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>5106.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>227371</td>\n",
       "      <td>175687.0</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.028463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>31931.0</td>\n",
       "      <td>14728.0</td>\n",
       "      <td>26692.0</td>\n",
       "      <td>22778.0</td>\n",
       "      <td>4748.0</td>\n",
       "      <td>3966.0</td>\n",
       "      <td>40375.0</td>\n",
       "      <td>13846.0</td>\n",
       "      <td>4825.0</td>\n",
       "      <td>7124.0</td>\n",
       "      <td>3333.0</td>\n",
       "      <td>4033.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>182870</td>\n",
       "      <td>141091.0</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>0.022892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>31628.0</td>\n",
       "      <td>14236.0</td>\n",
       "      <td>24880.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>40709.0</td>\n",
       "      <td>15002.0</td>\n",
       "      <td>5153.0</td>\n",
       "      <td>6540.0</td>\n",
       "      <td>3571.0</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>180691</td>\n",
       "      <td>137876.0</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.022619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         INFJ     ENTP     INTP     INTJ    ENTJ    ENFJ     INFP     ENFP  \\\n",
       "Word                                                                         \n",
       "i     67821.0  27381.0  52046.0  43810.0  8875.0  8683.0  87642.0  31156.0   \n",
       "the   39658.0  18993.0  35864.0  30497.0  6132.0  5018.0  48004.0  16454.0   \n",
       "to    40231.0  17852.0  33005.0  28753.0  5889.0  5471.0  48996.0  16945.0   \n",
       "a     31931.0  14728.0  26692.0  22778.0  4748.0  3966.0  40375.0  13846.0   \n",
       "and   31628.0  14236.0  24880.0  21568.0  4564.0  4343.0  40709.0  15002.0   \n",
       "\n",
       "         ISFP     ISTP    ISFJ    ISTJ    ESTP    ESFP    ESTJ    ESFJ  \\\n",
       "Word                                                                     \n",
       "i     11148.0  13883.0  8037.0  8169.0  3704.0  1696.0  1856.0  2166.0   \n",
       "the    6131.0   8893.0  4111.0  5141.0  2191.0   937.0  1000.0  1200.0   \n",
       "to     6264.0   8725.0  4607.0  5106.0  2254.0   972.0  1078.0  1223.0   \n",
       "a      4825.0   7124.0  3333.0  4033.0  1868.0   796.0   841.0   986.0   \n",
       "and    5153.0   6540.0  3571.0  3827.0  1905.0   834.0   943.0   988.0   \n",
       "\n",
       "         all         I    I_perc  all_perc  \n",
       "Word                                        \n",
       "i     378073  292556.0  0.047701  0.047328  \n",
       "the   230224  178299.0  0.029071  0.028820  \n",
       "to    227371  175687.0  0.028646  0.028463  \n",
       "a     182870  141091.0  0.023005  0.022892  \n",
       "and   180691  137876.0  0.022481  0.022619  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.sort_values(by='all', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vguk_YpZVABC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# calculate chi2\n",
    "df_bow['chi2_i'] = np.power((df_bow['I_perc'] - df_bow['all_perc']), 2) / df_bow['all_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOesPcaXVABD",
    "outputId": "b973bca5-2d74-4cdd-9a71-fc9956c0914f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_perc</th>\n",
       "      <th>all_perc</th>\n",
       "      <th>chi2_i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>urlweb</th>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infp</th>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infj</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infps</th>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infjs</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intp</th>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intps</th>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.047701</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.012176</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          I_perc  all_perc    chi2_i\n",
       "Word                                \n",
       "urlweb  0.002817  0.002615  0.000016\n",
       "infp    0.001249  0.001118  0.000015\n",
       "infj    0.001111  0.001019  0.000008\n",
       "infps   0.000466  0.000413  0.000007\n",
       "infjs   0.000393  0.000347  0.000006\n",
       "intp    0.000936  0.000871  0.000005\n",
       "my      0.012057  0.011859  0.000003\n",
       "intps   0.000346  0.000315  0.000003\n",
       "i       0.047701  0.047328  0.000003\n",
       "in      0.012361  0.012176  0.000003"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow[['I_perc', 'all_perc', 'chi2_i']][df_bow['I_perc'] > df_bow['all_perc']].sort_values(by='chi2_i', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dySRM0KqVABE"
   },
   "source": [
    "And there it is! What can we conclude from this?\n",
    "\n",
    "Looking at the top words with higher chi-square values, we can see that words like \"urlweb,\" \"infp,\" \"infj,\" as well as \"i\" have the top chi-square values compared to others. This indicates that these words are used more frequently by introverts than would be expected based on their overall occurrence in the dataset.\n",
    "\n",
    "The word \"I\" appears 9th in the top 10 highest chi-square values of 0.000003, suggesting that its usage by introverts deviates significantly from what would be expected based on its general frequency.\n",
    "\n",
    "Therefore, based on these findings, we can conclude that introverts tend to use \"I\" more frequently than extroverts, supporting the hypothesis that introverts favour the use of the word \"I.\"\n",
    "\n",
    "Let's now have a look at the words most used by extroverts following the same process but for extovert types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_perc</th>\n",
       "      <th>all_perc</th>\n",
       "      <th>chi2_e</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enfp</th>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entp</th>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entps</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfps</th>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entj</th>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfj</th>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estp</th>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entjs</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enfjs</th>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ne</th>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.015607</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7w6</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7w8</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         E_perc  all_perc    chi2_e\n",
       "Word                               \n",
       "enfp   0.001632  0.000728  0.001124\n",
       "entp   0.001474  0.000631  0.001124\n",
       "entps  0.000599  0.000226  0.000619\n",
       "enfps  0.000555  0.000228  0.000468\n",
       "entj   0.000738  0.000360  0.000397\n",
       "enfj   0.000631  0.000356  0.000213\n",
       "estp   0.000517  0.000289  0.000181\n",
       "entjs  0.000241  0.000105  0.000176\n",
       "d      0.000657  0.000424  0.000127\n",
       "enfjs  0.000220  0.000106  0.000122\n",
       "ne     0.000504  0.000312  0.000118\n",
       "you    0.016918  0.015607  0.000110\n",
       "7w6    0.000102  0.000038  0.000107\n",
       "7w8    0.000078  0.000027  0.000098\n",
       "he     0.003015  0.002530  0.000093"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract extrovert types only from all the personality types\n",
    "intro_types_e = [p for p in type_labels if p[0] == 'E']\n",
    "#Create an extrovert total word count column, which sums the counts of all extrovert columns\n",
    "df_bow['E'] = df_bow[intro_types_e].sum(axis=1)\n",
    "#calculate and add percentage column for extroverts\n",
    "df_bow['E_perc'] = df_bow['E'] / df_bow['E'].sum()\n",
    "# calculate chi2 for extroverts\n",
    "df_bow['chi2_e'] = np.power((df_bow['E_perc'] - df_bow['all_perc']), 2) / df_bow['all_perc']\n",
    "df_bow[['E_perc', 'all_perc', 'chi2_e']][df_bow['E_perc'] > df_bow['all_perc']].sort_values(by='chi2_e', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the chi-squared analysis, there is evidence to suggest that extroverts tend to use words like \"enfp\", \"entp\", \"entps\", and \"enfps\" as well as \"you\" more frequently compared to their overall usage. This supports our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlO1q-zlVABg"
   },
   "source": [
    "### n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXZa-xFeVABh"
   },
   "source": [
    "While individual words do carry meaning, it is often the case that combinations of words change meanings of sentences entirely.  For example, what difference does removing the `not` from a sentence make?\n",
    "\n",
    "Natural Language Processing is **not** easy!\n",
    "\n",
    "n-grams are a method to extract combinations of words into features for model building.  The `n` in n-grams specifies the number of tokens to include.  For example, a 2-gram returns all the consecutive pairs of words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGJEya0iVABi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-W1NOt4VABi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def word_grams(words, min_n=1, max_n=4):\n",
    "    s = []\n",
    "    for n in range(min_n, max_n):\n",
    "        for ngram in ngrams(words, n):\n",
    "            s.append(' '.join(str(i) for i in ngram))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uyHBnmoVABj",
    "outputId": "c5408f67-e2e2-40a6-a7c4-e31c5c359853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', 'three', 'four', 'one two', 'two three', 'three four', 'one two three', 'two three four']\n"
     ]
    }
   ],
   "source": [
    "print (word_grams('one two three four'.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine consecutive words into groups of 2 using n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jR-KSHUVABm",
    "outputId": "b2a4e948-4a7b-4c86-9a98-b2f530bd3174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'find'),\n",
       " ('find', 'all'),\n",
       " ('all', 'of'),\n",
       " ('of', 'you'),\n",
       " ('you', 'to'),\n",
       " ('to', 'be'),\n",
       " ('be', 'extremely'),\n",
       " ('extremely', 'humorous'),\n",
       " ('humorous', 'now'),\n",
       " ('now', 'to'),\n",
       " ('to', 'find'),\n",
       " ('find', 'other'),\n",
       " ('other', 'specimen'),\n",
       " ('specimen', 'to'),\n",
       " ('to', 'observe')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in ngrams(all_mbti.iloc[55555]['tokens'], 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine consecutive words into groups of 3 using n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVUBu-36VABo",
    "outputId": "882045f8-7e10-4f47-d939-bf127459d543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'find', 'all'),\n",
       " ('find', 'all', 'of'),\n",
       " ('all', 'of', 'you'),\n",
       " ('of', 'you', 'to'),\n",
       " ('you', 'to', 'be'),\n",
       " ('to', 'be', 'extremely'),\n",
       " ('be', 'extremely', 'humorous'),\n",
       " ('extremely', 'humorous', 'now'),\n",
       " ('humorous', 'now', 'to'),\n",
       " ('now', 'to', 'find'),\n",
       " ('to', 'find', 'other'),\n",
       " ('find', 'other', 'specimen'),\n",
       " ('other', 'specimen', 'to'),\n",
       " ('specimen', 'to', 'observe')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in ngrams(all_mbti.iloc[55555]['tokens'], 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sm4dVWzVABG"
   },
   "source": [
    "## Now that we understand all of that, let's cheat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUvfk_qrVABG"
   },
   "source": [
    "**Praise be to Python...**\n",
    "\n",
    "`sklearn` has a built in text feature extraction module called [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) that will literally do all of that work in one line of code! This function will convert a collection of documents (rows of text) into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTbEo8uEVABH",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fe57kvsHVABI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "# Fit the CountVectorizer on the preprocessed 'post' column\n",
    "vect.fit(all_mbti['post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFzCFS89VABM"
   },
   "source": [
    "### Tuning the vectorizer\n",
    "\n",
    "We have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune with examples on how to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqeL2KJ4VABR"
   },
   "source": [
    "- **stop_words:** string 'english', list, or None (default)\n",
    "    * If 'english', a built-in stop word list for English is used.\n",
    "    * If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    * If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzEOoIt0VABR",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WglDIhfhVABU"
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wx1TyjjVABU",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfz8TkhbVABW"
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5B_nbBDVABW",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CMv962vVABY"
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8OcjOK9VABZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GTogGUiVABa"
   },
   "source": [
    "### Guidelines for tuning CountVectorizer:\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!\n",
    "\n",
    "Finally, let's fit a tuned CountVectorizer to the MBTI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTPnl452VABa",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "betterVect = CountVectorizer(stop_words='english', \n",
    "                             min_df=2, \n",
    "                             max_df=0.5, \n",
    "                             ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsB226qGVABc",
    "outputId": "d68d31e5-b3d4-4a3f-bb91-97724bf9521e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.5, min_df=2, stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(max_df=0.5, min_df=2, stop_words=&#x27;english&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.5, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betterVect.fit(all_mbti['post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After vectorization using `CountVectorizer`, we can view the transformed data as a matrix where each row represents a document (post in our case) and each column represents a unique word in the vocabulary. The cell values indicate the count of the corresponding word in each document.\n",
    "\n",
    "It's essential to note that this process generates a very large dataset, potentially consuming significant memory on your machine.\n",
    "\n",
    "Uncomment the code below if you would still want to view the vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      00  000  0000  00001010  001  00100000  00100001  00101100  00101110  \\\n",
      "0      0    0     0         0    0         0         0         0         0   \n",
      "1      0    0     0         0    0         0         0         0         0   \n",
      "2      0    0     0         0    0         0         0         0         0   \n",
      "3      0    0     0         0    0         0         0         0         0   \n",
      "4      0    0     0         0    0         0         0         0         0   \n",
      "...   ..  ...   ...       ...  ...       ...       ...       ...       ...   \n",
      "9995   0    0     0         0    0         0         0         0         0   \n",
      "9996   0    0     0         0    0         0         0         0         0   \n",
      "9997   0    0     0         0    0         0         0         0         0   \n",
      "9998   0    0     0         0    0         0         0         0         0   \n",
      "9999   0    0     0         0    0         0         0         0         0   \n",
      "\n",
      "      002  ...  čeština  συντηετιψ  помоћ  послато  са  соционика  тапатока  \\\n",
      "0       0  ...        0          0      0        0   0          0         0   \n",
      "1       0  ...        0          0      0        0   0          0         0   \n",
      "2       0  ...        0          0      0        0   0          0         0   \n",
      "3       0  ...        0          0      0        0   0          0         0   \n",
      "4       0  ...        0          0      0        0   0          0         0   \n",
      "...   ...  ...      ...        ...    ...      ...  ..        ...       ...   \n",
      "9995    0  ...        0          0      0        0   0          0         0   \n",
      "9996    0  ...        0          0      0        0   0          0         0   \n",
      "9997    0  ...        0          0      0        0   0          0         0   \n",
      "9998    0  ...        0          0      0        0   0          0         0   \n",
      "9999    0  ...        0          0      0        0   0          0         0   \n",
      "\n",
      "      уз  ಠಠ  ﾟﾟ  \n",
      "0      0   0   0  \n",
      "1      0   0   0  \n",
      "2      0   0   0  \n",
      "3      0   0   0  \n",
      "4      0   0   0  \n",
      "...   ..  ..  ..  \n",
      "9995   0   0   0  \n",
      "9996   0   0   0  \n",
      "9997   0   0   0  \n",
      "9998   0   0   0  \n",
      "9999   0   0   0  \n",
      "\n",
      "[10000 rows x 50426 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Transform the training data\n",
    "vectorized_data = betterVect.transform(all_mbti['post'][0:10000,])\n",
    "\n",
    "# Convert the sparse matrix to a dense array for easier viewing (optional)\n",
    "dense_vectorized_data = vectorized_data.toarray()\n",
    "\n",
    "# Create a DataFrame to display the vectorized data\n",
    "vectorized_df = pd.DataFrame(dense_vectorized_data, columns=betterVect.get_feature_names_out())\n",
    "\n",
    "# Display the vectorized DataFrame\n",
    "print(vectorized_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this train we covered various techniques for cleaning text data and extracting features to use with machine learning models. We also demonstrated how NLTK's `CountVectorizer` can be used to clean text data and extract features, transforming the text data into a matrix of numbers that can be fed into a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VCXae5QXU__Z",
    "wzM8TbWBU__h",
    "FvA-QZmRU__r",
    "hAUkklVXU__6",
    "rFln-NFtVAAI",
    "UZomXVzoVAAR",
    "qp-n688CVAAc",
    "tGmGzrbsVAAf",
    "oFzCFS89VABM",
    "TlO1q-zlVABg"
   ],
   "name": "3_How-do-machines-understand language.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
